Index: include/llvm/ADT/ilist_node.h
===================================================================
--- include/llvm/ADT/ilist_node.h	(revision 277823)
+++ include/llvm/ADT/ilist_node.h	(working copy)
@@ -70,7 +70,7 @@
     const NodeTy *Prev = this->getPrev();
 
     // Check for sentinel.
-    if (!Prev->getNext())
+    if (!Prev || !Prev->getNext())
       return nullptr;
 
     return Prev;
@@ -81,7 +81,7 @@
     NodeTy *Next = getNext();
 
     // Check for sentinel.
-    if (!Next->getNext())
+    if (!Next || !Next->getNext())
       return nullptr;
 
     return Next;
Index: include/llvm/CodeGen/AsmPrinter.h
===================================================================
--- include/llvm/CodeGen/AsmPrinter.h	(revision 277823)
+++ include/llvm/CodeGen/AsmPrinter.h	(working copy)
@@ -199,9 +199,10 @@
 
   /// Emit the specified function out to the OutStreamer.
   bool runOnMachineFunction(MachineFunction &MF) override {
+    bool modified = TagCallSites(MF);
     SetupMachineFunction(MF);
     EmitFunctionBody();
-    return false;
+    return modified;
   }
 
   //===------------------------------------------------------------------===//
@@ -393,6 +394,14 @@
     EmitLabelPlusOffset(Label, 0, Size, IsSectionRelative);
   }
 
+  /// Find the stackmap intrinsic associated with a function call
+  MachineInstr *FindStackMap(MachineBasicBlock &MBB,
+                             MachineInstr *MI) const;
+
+  /// Move stackmap intrinsics directly after calls to correctly capture
+  /// return addresses
+  bool TagCallSites(MachineFunction &MF);
+
   //===------------------------------------------------------------------===//
   // Dwarf Emission Helper Routines
   //===------------------------------------------------------------------===//
Index: include/llvm/CodeGen/MachineFunction.h
===================================================================
--- include/llvm/CodeGen/MachineFunction.h	(revision 277823)
+++ include/llvm/CodeGen/MachineFunction.h	(working copy)
@@ -20,6 +20,7 @@
 
 #include "llvm/ADT/ilist.h"
 #include "llvm/CodeGen/MachineBasicBlock.h"
+#include "llvm/IR/Instructions.h"
 #include "llvm/IR/DebugLoc.h"
 #include "llvm/IR/Metadata.h"
 #include "llvm/Support/Allocator.h"
@@ -84,6 +85,18 @@
 };
 
 class MachineFunction {
+  // Mappings between IR values and stack slots
+  typedef DenseMap<const Value*, int> ValStackSlotMap;
+  typedef std::pair<const Value*, int> ValStackSlotPair;
+  typedef DenseMap<const Instruction*, ValStackSlotMap> InstOpStackSlotMap;
+  typedef std::pair<const Instruction*, ValStackSlotMap> InstOpStackSlotPair;
+
+  // Mappings between IR values and physical registers
+  typedef DenseMap<const Value*, unsigned> ValPhysRegMap;
+  typedef std::pair<const Value*, unsigned> ValPhysRegPair;
+  typedef DenseMap<const Instruction*, ValPhysRegMap> InstOpPhysRegMap;
+  typedef std::pair<const Instruction*, ValPhysRegMap> InstOpPhysRegPair;
+
   const Function *Fn;
   const TargetMachine &Target;
   const TargetSubtargetInfo *STI;
@@ -145,6 +158,23 @@
   /// True if the function includes any inline assembly.
   bool HasInlineAsm;
 
+  /// Map from stackmap operands to spilled stack slots
+  InstOpStackSlotMap SMOp2StackSlot;
+
+  /// Map from stackmap operands to physical registers
+  InstOpPhysRegMap SMOp2PhysReg;
+
+  // TODO the next two maps should actually contain sets of backing slots &
+  // duplicate physical registers rather than being restricted to one of each
+
+  /// Map from stackmap operands to spilled stack slots, for operands in
+  /// physical registers that have a backing stack slot
+  InstOpStackSlotMap SMOp2BackingStackSlot;
+
+  /// Map from stackmap operands to physical registers, for operands that
+  /// are duplicated across several registers
+  InstOpPhysRegMap SMOp2DupPhysReg;
+
   MachineFunction(const MachineFunction &) = delete;
   void operator=(const MachineFunction&) = delete;
 public:
@@ -457,6 +487,9 @@
     return Mask;
   }
 
+  /// Is a register caller-saved?
+  bool isCallerSaved(unsigned Reg) const;
+
   /// allocateMemRefsArray - Allocate an array to hold MachineMemOperand
   /// pointers.  This array is owned by the MachineFunction.
   MachineInstr::mmo_iterator allocateMemRefsArray(unsigned long Num);
@@ -488,6 +521,55 @@
   /// getPICBaseSymbol - Return a function-local symbol to represent the PIC
   /// base.
   MCSymbol *getPICBaseSymbol() const;
+
+  //===--------------------------------------------------------------------===//
+  // StackMap IR/physical location mappings
+  //
+
+  /// Add an IR/stack slot mapping for a stackmap operand
+  void addSMOpStackSlotMapping(const CallInst *SM, const Value *Val, int SS);
+  void addSMOpStackSlotMapping(const CallInst *SM, unsigned Op, int SS);
+
+  /// Update stack slot references to new indexes after stack slot coloring
+  void updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes);
+
+  /// Return the stack slot mapped to a stackmap operand
+  int getSMStackSlot(const CallInst *SM, const Value *Val) const;
+  int getSMStackSlot(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/physical register mapping for a stackmap operand
+  void addSMOpPhysRegMapping(const CallInst *SM, const Value *Val, unsigned Reg);
+  void addSMOpPhysRegMapping(const CallInst *SM, unsigned Op, unsigned Reg);
+
+  /// Return the physical register mapped to a stackmap operand
+  unsigned getSMPhysReg(const CallInst *SM, const Value *Val) const;
+  unsigned getSMPhysReg(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/stack slot mapping for a stackmap operand in a physical
+  /// register with a backing stack slot
+  void addSMOpBackingStackSlot(const CallInst *SM, const Value *Val, int SS);
+  void addSMOpBackingStackSlot(const CallInst *SM, unsigned Op, int SS);
+
+  /// Update stack slot references to new indexes after stack slot coloring
+  void updateSMBackingStackSlotRefs(SmallDenseMap<int, int, 16> &Changes);
+
+  // TODO should return a set of backing stack slots
+
+  /// Return the backing stack slot for a stackmap operand mapped to a physical
+  /// register
+  int getSMBackingStackSlot(const CallInst *SM, const Value *Val) const;
+  int getSMBackingStackSlot(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/physical register mapping for a stackmap operand with duplicate
+  /// physical registers
+  void addSMOpDupPhysRegMapping(const CallInst *SM, const Value *Val, unsigned Reg);
+  void addSMOpDupPhysRegMapping(const CallInst *SM, unsigned Op, unsigned Reg);
+
+  // TODO should return a set of duplicate registers
+
+  /// Return the duplicate physical register mapped to a stackmap operand
+  unsigned getSMDupPhysReg(const CallInst *SM, const Value *Val) const;
+  unsigned getSMDupPhysReg(const CallInst *SM, unsigned Op) const;
 };
 
 //===--------------------------------------------------------------------===//
Index: include/llvm/CodeGen/Passes.h
===================================================================
--- include/llvm/CodeGen/Passes.h	(revision 277823)
+++ include/llvm/CodeGen/Passes.h	(working copy)
@@ -448,6 +448,10 @@
   // instruction and update the MachineFunctionInfo with that information.
   extern char &ShrinkWrapID;
 
+  /// Stack transformation metadata pass.  Gather additional stack
+  /// transformation metadata from machine functions.
+  extern char &StackTransformMetadataID;
+
   /// VirtRegRewriter pass. Rewrite virtual registers to physical registers as
   /// assigned in VirtRegMap.
   extern char &VirtRegRewriterID;
Index: include/llvm/CodeGen/StackMaps.h
===================================================================
--- include/llvm/CodeGen/StackMaps.h	(revision 277823)
+++ include/llvm/CodeGen/StackMaps.h	(working copy)
@@ -142,9 +142,16 @@
     unsigned Size;
     unsigned Reg;
     int64_t Offset;
-    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0) {}
-    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset)
-        : Type(Type), Size(Size), Reg(Reg), Offset(Offset) {}
+    bool Ptr;
+    bool Alloca;
+    bool Duplicate;
+    unsigned PtrDataSize;
+    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0),
+                 Ptr(false), Alloca(false), Duplicate(false), PtrDataSize(0) {}
+    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset,
+             bool Ptr, bool Alloca, bool Duplicate, unsigned PtrDataSize)
+        : Type(Type), Size(Size), Reg(Reg), Offset(Offset), Ptr(Ptr),
+          Alloca(Alloca), Duplicate(Duplicate), PtrDataSize(PtrDataSize) {}
   };
 
   struct LiveOutReg {
@@ -195,15 +202,17 @@
   typedef MapVector<const MCSymbol *, uint64_t> FnStackSizeMap;
 
   struct CallsiteInfo {
+    const MCSymbol *Func;
     const MCExpr *CSOffsetExpr;
     uint64_t ID;
     LocationVec Locations;
     LiveOutVec LiveOuts;
-    CallsiteInfo() : CSOffsetExpr(nullptr), ID(0) {}
-    CallsiteInfo(const MCExpr *CSOffsetExpr, uint64_t ID,
-                 LocationVec &&Locations, LiveOutVec &&LiveOuts)
-        : CSOffsetExpr(CSOffsetExpr), ID(ID), Locations(std::move(Locations)),
-          LiveOuts(std::move(LiveOuts)) {}
+    CallsiteInfo() : Func(nullptr), CSOffsetExpr(nullptr), ID(0) {}
+    CallsiteInfo(const MCSymbol *Func, const MCExpr *CSOffsetExpr,
+                 uint64_t ID, LocationVec &&Locations,
+                 LiveOutVec &&LiveOuts)
+        : Func(Func), CSOffsetExpr(CSOffsetExpr), ID(ID),
+          Locations(std::move(Locations)), LiveOuts(std::move(LiveOuts)) {}
   };
 
   typedef std::vector<CallsiteInfo> CallsiteInfoList;
@@ -213,10 +222,14 @@
   ConstantPool ConstPool;
   FnStackSizeMap FnStackSize;
 
+  /// Get pointer information for stackmap operand
+  void getPointerInfo(const Value *Op, const DataLayout &DL, bool &isPtr,
+                      bool &isAlloca, unsigned &PtrDataSize) const;
+
   MachineInstr::const_mop_iterator
   parseOperand(MachineInstr::const_mop_iterator MOI,
                MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-               LiveOutVec &LiveOuts) const;
+               LiveOutVec &LiveOuts, User::const_op_iterator &Op) const;
 
   /// \brief Create a live-out register record for the given register @p Reg.
   LiveOutReg createLiveOutReg(unsigned Reg,
Index: include/llvm/InitializePasses.h
===================================================================
--- include/llvm/InitializePasses.h	(revision 277823)
+++ include/llvm/InitializePasses.h	(working copy)
@@ -263,6 +263,7 @@
 void initializeStackProtectorPass(PassRegistry&);
 void initializeStackColoringPass(PassRegistry&);
 void initializeStackSlotColoringPass(PassRegistry&);
+void initializeStackTransformMetadataPass(PassRegistry&);
 void initializeStraightLineStrengthReducePass(PassRegistry &);
 void initializeStripDeadDebugInfoPass(PassRegistry&);
 void initializeStripDeadPrototypesPassPass(PassRegistry&);
Index: lib/CodeGen/AsmPrinter/AsmPrinter.cpp
===================================================================
--- lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(revision 277823)
+++ lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(working copy)
@@ -1160,6 +1160,41 @@
   return CurExceptionSym;
 }
 
+MachineInstr *AsmPrinter::FindStackMap(MachineBasicBlock &MBB,
+                                       MachineInstr *MI) const {
+  MachineBasicBlock::instr_iterator i, ie;
+  for(i = MI->getNextNode(), ie = MBB.instr_end();
+      i != ie;
+      i = i->getNextNode()) {
+    if(i->getOpcode() == TargetOpcode::STACKMAP)
+      return &*i;
+    else if(i->isCall())
+      break;
+  }
+
+  // Call site without a stackmap implies that either the call was generated by
+  // the backend or the LLVM bitcode was never instrumented by the StackInfo
+  // pass.  This is not necessarily an error!
+  return nullptr;
+}
+
+bool AsmPrinter::TagCallSites(MachineFunction &MF) {
+  bool tagged = false;
+  for(auto MBB = MF.begin(), MBBE = MF.end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), MIE = MBB->instr_end(); MI != MIE; MI++) {
+      if(MI->isCall() && !MI->isPseudo()) {
+        MachineInstr *SMI = FindStackMap(*MBB, &*MI);
+        if(SMI != nullptr) {
+          MBB->remove(SMI);
+          MI = MBB->insert(++MI, SMI);
+          tagged = true;
+        }
+      }
+    }
+  }
+  return tagged;
+}
+
 void AsmPrinter::SetupMachineFunction(MachineFunction &MF) {
   this->MF = &MF;
   // Get the function symbol.
Index: lib/CodeGen/CMakeLists.txt
===================================================================
--- lib/CodeGen/CMakeLists.txt	(revision 277823)
+++ lib/CodeGen/CMakeLists.txt	(working copy)
@@ -111,6 +111,7 @@
   StackSlotColoring.cpp
   StackMapLivenessAnalysis.cpp
   StackMaps.cpp
+  StackTransformMetadata.cpp
   StatepointExampleGC.cpp
   TailDuplication.cpp
   TargetFrameLoweringImpl.cpp
Index: lib/CodeGen/CodeGen.cpp
===================================================================
--- lib/CodeGen/CodeGen.cpp	(revision 277823)
+++ lib/CodeGen/CodeGen.cpp	(working copy)
@@ -68,6 +68,7 @@
   initializeStackMapLivenessPass(Registry);
   initializeStackProtectorPass(Registry);
   initializeStackSlotColoringPass(Registry);
+  initializeStackTransformMetadataPass(Registry);
   initializeTailDuplicatePassPass(Registry);
   initializeTargetPassConfigPass(Registry);
   initializeTwoAddressInstructionPassPass(Registry);
Index: lib/CodeGen/MachineFunction.cpp
===================================================================
--- lib/CodeGen/MachineFunction.cpp	(revision 277823)
+++ lib/CodeGen/MachineFunction.cpp	(working copy)
@@ -253,6 +253,15 @@
                                MMO->getBaseAlignment());
 }
 
+/// Is a register caller-saved?
+bool MachineFunction::isCallerSaved(unsigned Reg) const {
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+  CallingConv::ID CC = Fn->getCallingConv();
+  const uint32_t *Mask =
+    RegInfo->getTargetRegisterInfo()->getCallPreservedMask(*this, CC);
+  return !((Mask[Reg / 32] >> Reg % 32) & 1);
+}
+
 MachineInstr::mmo_iterator
 MachineFunction::allocateMemRefsArray(unsigned long Num) {
   return Allocator.Allocate<MachineMemOperand *>(Num);
@@ -482,6 +491,281 @@
                                Twine(getFunctionNumber()) + "$pb");
 }
 
+/// Add an IR/stack slot mapping for a stackmap operand
+void MachineFunction::addSMOpStackSlotMapping(const CallInst *SM,
+                                              const Value *Val,
+                                              int SS) {
+  InstOpStackSlotMap::iterator it;
+  std::pair<InstOpStackSlotMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(FrameInfo->getObjectIndexBegin() <= SS &&
+         SS < FrameInfo->getObjectIndexEnd() &&
+         !FrameInfo->isDeadObjectIndex(SS) &&
+         "Invalid stack slot");
+
+  if((it = SMOp2StackSlot.find(SM)) == SMOp2StackSlot.end())
+  {
+    ValStackSlotMap NewMap;
+    ins = SMOp2StackSlot.insert(InstOpStackSlotPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+  it->second.insert(ValStackSlotPair(Val, SS));
+}
+
+void MachineFunction::addSMOpStackSlotMapping(const CallInst *SM,
+                                              unsigned Op,
+                                              int SS) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpStackSlotMapping(SM, SM->getArgOperand(Op), SS);
+}
+
+/// Update stack slot references to new indexes after stack slot coloring
+void
+MachineFunction::updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes) {
+  if(Changes.size()) {
+    DEBUG(dbgs() << "Updating stackmap stack slot references\n";);
+
+    // Iterate over all stackmaps
+    InstOpStackSlotMap::iterator i, ie;
+    for(i = SMOp2StackSlot.begin(), ie = SMOp2StackSlot.end(); i != ie; i++) {
+      // Iterate over all operand/stack slot mappings
+      ValStackSlotMap &Map = i->second;
+      ValStackSlotMap::iterator j, je;
+      for(j = Map.begin(), je = Map.end(); j != je; j++) {
+        SmallDenseMap<int, int, 16>::iterator it;
+        if((it = Changes.find(j->second)) != Changes.end()) {
+          DEBUG(
+            j->first->printAsOperand(dbgs());
+            dbgs() << ": from stack slot " << j->second << " to "
+                   << it->second << "\n";
+          );
+          j->second = it->second;
+        }
+      }
+    }
+  }
+}
+
+/// Return the stack slot mapped to a stackmap operand
+int MachineFunction::getSMStackSlot(const CallInst *SM,
+                                    const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpStackSlotMap::const_iterator i = SMOp2StackSlot.find(SM);
+  if(i != SMOp2StackSlot.end())
+  {
+    ValStackSlotMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return INT_MAX;
+}
+
+int MachineFunction::getSMStackSlot(const CallInst *SM, unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMStackSlot(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/physical register mapping for a stackmap operand
+void MachineFunction::addSMOpPhysRegMapping(const CallInst *SM,
+                                            const Value *Val,
+                                            unsigned Reg) {
+  InstOpPhysRegMap::iterator it;
+  std::pair<InstOpPhysRegMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+
+  if((it = SMOp2PhysReg.find(SM)) == SMOp2PhysReg.end())
+  {
+    ValPhysRegMap NewMap;
+    ins = SMOp2PhysReg.insert(InstOpPhysRegPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+  it->second.insert(ValPhysRegPair(Val, Reg));
+}
+
+void MachineFunction::addSMOpPhysRegMapping(const CallInst *SM,
+                                            unsigned Op,
+                                            unsigned Reg) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpPhysRegMapping(SM, SM->getArgOperand(Op), Reg);
+}
+
+/// Return the physical register mapped to a stackmap operand
+unsigned MachineFunction::getSMPhysReg(const CallInst *SM,
+                                       const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpPhysRegMap::const_iterator i = SMOp2PhysReg.find(SM);
+  if(i != SMOp2PhysReg.end())
+  {
+    ValPhysRegMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return UINT_MAX;
+}
+
+unsigned MachineFunction::getSMPhysReg(const CallInst *SM,
+                                       unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMPhysReg(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/stack slot mapping for a stackmap operand in a physical register
+/// with a backing stack slot
+void MachineFunction::addSMOpBackingStackSlot(const CallInst *SM,
+                                              const Value *Val,
+                                              int SS) {
+  InstOpStackSlotMap::iterator it;
+  std::pair<InstOpStackSlotMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(FrameInfo->getObjectIndexBegin() <= SS &&
+         SS < FrameInfo->getObjectIndexEnd() &&
+         !FrameInfo->isDeadObjectIndex(SS) &&
+         "Invalid stack slot");
+
+  if((it = SMOp2BackingStackSlot.find(SM)) == SMOp2BackingStackSlot.end())
+  {
+    ValStackSlotMap NewMap;
+    ins = SMOp2BackingStackSlot.insert(InstOpStackSlotPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+
+  // TODO allow multiple backing slots
+  ValStackSlotMap::iterator valIt = it->second.find(Val);
+  if(valIt == it->second.end()) it->second.insert(ValStackSlotPair(Val, SS));
+  else assert(valIt->second == SS && "Multiple backing slots");
+}
+
+void MachineFunction::addSMOpBackingStackSlot(const CallInst *SM,
+                                           unsigned Op,
+                                           int SS) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpBackingStackSlot(SM, SM->getArgOperand(Op), SS);
+}
+
+/// Update stack slot references to new indexes after stack slot coloring
+void MachineFunction::updateSMBackingStackSlotRefs(SmallDenseMap<int,
+                                                              int,
+                                                              16> &Changes) {
+  if(Changes.size()) {
+    DEBUG(dbgs() << "Updating stackmap backing stack slot references\n";);
+
+    // Iterate over all stackmaps
+    InstOpStackSlotMap::iterator i, ie;
+    for(i = SMOp2BackingStackSlot.begin(), ie = SMOp2BackingStackSlot.end();
+        i != ie;
+        i++) {
+      // Iterate over all operand/stack slot mappings
+      ValStackSlotMap &Map = i->second;
+      ValStackSlotMap::iterator j, je;
+      for(j = Map.begin(), je = Map.end(); j != je; j++) {
+        SmallDenseMap<int, int, 16>::iterator it;
+        if((it = Changes.find(j->second)) != Changes.end()) {
+          DEBUG(
+            j->first->printAsOperand(dbgs());
+            dbgs() << ": from stack slot " << j->second << " to "
+                   << it->second << "\n";
+          );
+          j->second = it->second;
+        }
+      }
+    }
+  }
+}
+
+/// Return the backing stack slot for a stackmap operand mapped to a physical
+/// register
+int MachineFunction::getSMBackingStackSlot(const CallInst *SM,
+                                        const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpStackSlotMap::const_iterator i = SMOp2BackingStackSlot.find(SM);
+  if(i != SMOp2BackingStackSlot.end())
+  {
+    ValStackSlotMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return INT_MAX;
+}
+
+int MachineFunction::getSMBackingStackSlot(const CallInst *SM, unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMBackingStackSlot(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/physical register mapping for a stackmap operand
+void MachineFunction::addSMOpDupPhysRegMapping(const CallInst *SM,
+                                               const Value *Val,
+                                               unsigned Reg) {
+  InstOpPhysRegMap::iterator it;
+  std::pair<InstOpPhysRegMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+
+  if((it = SMOp2DupPhysReg.find(SM)) == SMOp2DupPhysReg.end())
+  {
+    ValPhysRegMap NewMap;
+    ins = SMOp2DupPhysReg.insert(InstOpPhysRegPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+
+  // TODO allow multiple duplicate registers
+  ValPhysRegMap::iterator valIt = it->second.find(Val);
+  if(valIt == it->second.end()) it->second.insert(ValStackSlotPair(Val, Reg));
+  else assert(valIt->second == Reg && "Multiple duplicate registers");
+}
+
+void MachineFunction::addSMOpDupPhysRegMapping(const CallInst *SM,
+                                               unsigned Op,
+                                               unsigned Reg) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpDupPhysRegMapping(SM, SM->getArgOperand(Op), Reg);
+}
+
+/// Return the physical register mapped to a stackmap operand
+unsigned MachineFunction::getSMDupPhysReg(const CallInst *SM,
+                                          const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpPhysRegMap::const_iterator i = SMOp2DupPhysReg.find(SM);
+  if(i != SMOp2DupPhysReg.end())
+  {
+    ValPhysRegMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return UINT_MAX;
+}
+
+unsigned MachineFunction::getSMDupPhysReg(const CallInst *SM,
+                                          unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMDupPhysReg(SM, SM->getArgOperand(Op));
+}
+
 //===----------------------------------------------------------------------===//
 //  MachineFrameInfo implementation
 //===----------------------------------------------------------------------===//
Index: lib/CodeGen/Passes.cpp
===================================================================
--- lib/CodeGen/Passes.cpp	(revision 277823)
+++ lib/CodeGen/Passes.cpp	(working copy)
@@ -754,6 +754,10 @@
   // Allow targets to change the register assignments before rewriting.
   addPreRewrite();
 
+  // Gather additional stack transformation metadata before rewriting virtual
+  // registers
+  addPass(&StackTransformMetadataID);
+
   // Finally rewrite virtual registers.
   addPass(&VirtRegRewriterID);
 
Index: lib/CodeGen/RegAllocFast.cpp
===================================================================
--- lib/CodeGen/RegAllocFast.cpp	(revision 277823)
+++ lib/CodeGen/RegAllocFast.cpp	(working copy)
@@ -1078,6 +1078,12 @@
 /// runOnMachineFunction - Register allocate the whole function
 ///
 bool RAFast::runOnMachineFunction(MachineFunction &Fn) {
+  // TODO the fast register allocator behave poorly for stackmaps with lots
+  // of operands, and since it doesn't use the VirtRegRewriter pass we can't
+  // capture correct stackmap operand locations
+  assert(false && "fast register allocator not supported "
+                  "for stack transformation");
+
   DEBUG(dbgs() << "********** FAST REGISTER ALLOCATION **********\n"
                << "********** Function: " << Fn.getName() << '\n');
   MF = &Fn;
Index: lib/CodeGen/StackMaps.cpp
===================================================================
--- lib/CodeGen/StackMaps.cpp	(revision 277823)
+++ lib/CodeGen/StackMaps.cpp	(working copy)
@@ -13,6 +13,7 @@
 #include "llvm/CodeGen/MachineFunction.h"
 #include "llvm/CodeGen/MachineInstr.h"
 #include "llvm/IR/DataLayout.h"
+#include "llvm/IR/IntrinsicInst.h"
 #include "llvm/MC/MCContext.h"
 #include "llvm/MC/MCExpr.h"
 #include "llvm/MC/MCObjectFileInfo.h"
@@ -84,32 +85,63 @@
   return (unsigned)RegNum;
 }
 
+void StackMaps::getPointerInfo(const Value *Op,
+                               const DataLayout &DL,
+                               bool &isPtr, bool &isAlloca,
+                               unsigned &PtrDataSize) const {
+  isPtr = false;
+  isAlloca = false;
+  PtrDataSize = 0;
+
+  assert(Op != nullptr && "Invalid stackmap operand");
+  Type *Ty = Op->getType();
+  if(Ty->isPointerTy())
+  {
+    PointerType *PTy = cast<PointerType>(Ty);
+    if(PTy->getElementType()->isSized())
+    {
+      isPtr = true;
+      PtrDataSize = DL.getTypeAllocSize(PTy->getElementType());
+      if(isa<AllocaInst>(Op)) isAlloca = true;
+    }
+  }
+}
+
 MachineInstr::const_mop_iterator
 StackMaps::parseOperand(MachineInstr::const_mop_iterator MOI,
                         MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-                        LiveOutVec &LiveOuts) const {
+                        LiveOutVec &LiveOuts, User::const_op_iterator &Op) const {
+  bool isPtr, isAlloca;
+  unsigned PtrDataSize;
+  auto &DL = AP.MF->getDataLayout();
   const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  const Value *OpVal = Op->get();
+
   if (MOI->isImm()) {
+    getPointerInfo(OpVal, DL, isPtr, isAlloca, PtrDataSize);
     switch (MOI->getImm()) {
     default:
       llvm_unreachable("Unrecognized operand type.");
     case StackMaps::DirectMemRefOp: {
-      unsigned Size = AP.TM.getDataLayout()->getPointerSizeInBits();
+      unsigned Size = DL.getPointerSizeInBits();
       assert((Size % 8) == 0 && "Need pointer size in bytes.");
       Size /= 8;
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
       Locs.emplace_back(StackMaps::Location::Direct, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+                        getDwarfRegNum(Reg, TRI), Imm, isPtr, isAlloca, false,
+                        PtrDataSize);
       break;
     }
     case StackMaps::IndirectMemRefOp: {
       int64_t Size = (++MOI)->getImm();
+      int64_t AllocSize = DL.getTypeAllocSize(OpVal->getType());
       assert(Size > 0 && "Need a valid size for indirect memory locations.");
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
-      Locs.emplace_back(StackMaps::Location::Indirect, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+      Locs.emplace_back(StackMaps::Location::Indirect, AllocSize,
+                        getDwarfRegNum(Reg, TRI), Imm, isPtr, isAlloca, false,
+                        PtrDataSize);
       break;
     }
     case StackMaps::ConstantOp: {
@@ -116,10 +148,12 @@
       ++MOI;
       assert(MOI->isImm() && "Expected constant operand.");
       int64_t Imm = MOI->getImm();
-      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm);
+      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm,
+                        isPtr, isAlloca, false, PtrDataSize);
       break;
     }
     }
+    ++Op;
     return ++MOI;
   }
 
@@ -134,17 +168,101 @@
 
     assert(TargetRegisterInfo::isPhysicalRegister(MOI->getReg()) &&
            "Virtreg operands should have been rewritten before now.");
-    const TargetRegisterClass *RC = TRI->getMinimalPhysRegClass(MOI->getReg());
     assert(!MOI->getSubReg() && "Physical subreg still around.");
 
+    int64_t ID = MOI->getParent()->getOperand(0).getImm();
+    size_t valSize = DL.getTypeAllocSize(OpVal->getType());
+    getPointerInfo(OpVal, DL, isPtr, isAlloca, PtrDataSize);
+    const CallInst *SMIR = cast<CallInst>(Op->getUser());
+
+    // Check if it's been spilled to a stack slot
+    int SS = AP.MF->getSMStackSlot(SMIR, OpVal);
+    const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
+    if(MFI->getObjectIndexBegin() <= SS && SS < MFI->getObjectIndexEnd() &&
+       !MFI->isDeadObjectIndex(SS)) {
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": in stack slot " << SS << "\n";
+      );
+      int64_t Offset = MFI->getObjectOffset(SS) + 16; // RA + old FBP
+
+      Locs.emplace_back(StackMaps::Location::Indirect, valSize,
+                        getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI),
+                        Offset, isPtr, isAlloca, false, PtrDataSize);
+      ++Op;
+      return ++MOI;
+    }
+
+    // Check if it's been spilled to another register
+    unsigned PhysReg = AP.MF->getSMPhysReg(SMIR, OpVal);
+    if(!TargetRegisterInfo::isPhysicalRegister(PhysReg)) {
+      PhysReg = MOI->getReg();
+      if(AP.MF->isCallerSaved(PhysReg)) {
+        DEBUG(
+          dbgs() << "WARNING: ";
+          OpVal->printAsOperand(dbgs());
+          dbgs() << ": no spill location for caller-saved register "
+                 << getDwarfRegNum(PhysReg, TRI) << "\n";
+        );
+      }
+    }
+
     unsigned Offset = 0;
-    unsigned DwarfRegNum = getDwarfRegNum(MOI->getReg(), TRI);
+    unsigned DwarfRegNum = getDwarfRegNum(PhysReg, TRI);
     unsigned LLVMRegNum = TRI->getLLVMRegNum(DwarfRegNum, false);
-    unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, MOI->getReg());
+    unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, PhysReg);
     if (SubRegIdx)
       Offset = TRI->getSubRegIdxOffset(SubRegIdx);
 
-    Locs.emplace_back(Location::Register, RC->getSize(), DwarfRegNum, Offset);
+    DEBUG(
+      dbgs() << "Stackmap " << ID << ": ";
+      OpVal->printAsOperand(dbgs());
+      dbgs() << ": in register " << DwarfRegNum << "\n";
+    );
+
+    Locs.emplace_back(Location::Register, valSize, DwarfRegNum, Offset,
+                      isPtr, isAlloca, false, PtrDataSize);
+
+    // Check if there's a backing stack slot
+    // TODO should be able to generate records for multiple backing slots
+    SS = AP.MF->getSMBackingStackSlot(SMIR, OpVal);
+    if(MFI->getObjectIndexBegin() <= SS && SS < MFI->getObjectIndexEnd() &&
+       !MFI->isDeadObjectIndex(SS)) {
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": backed by stack slot " << SS << "\n";
+      );
+      int64_t Offset = MFI->getObjectOffset(SS) + 16; // RA + old FBP
+
+      Locs.emplace_back(StackMaps::Location::Indirect, valSize,
+                        getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI),
+                        Offset, isPtr, isAlloca, true, PtrDataSize);
+    }
+
+    // Check if there's a duplicate register
+    // TODO should be able to generate records multiple duplicates
+    PhysReg = AP.MF->getSMDupPhysReg(SMIR, OpVal);
+    if(TargetRegisterInfo::isPhysicalRegister(PhysReg)) {
+      Offset = 0;
+      DwarfRegNum = getDwarfRegNum(PhysReg, TRI);
+      LLVMRegNum = TRI->getLLVMRegNum(DwarfRegNum, false);
+      SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, PhysReg);
+      if (SubRegIdx)
+        Offset = TRI->getSubRegIdxOffset(SubRegIdx);
+
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": duplicated in register " << DwarfRegNum << "\n";
+      );
+
+      Locs.emplace_back(Location::Register, valSize, DwarfRegNum, Offset,
+                        isPtr, isAlloca, true, PtrDataSize);
+    }
+
+    ++Op;
     return ++MOI;
   }
 
@@ -285,6 +403,7 @@
   MCContext &OutContext = AP.OutStreamer->getContext();
   MCSymbol *MILabel = OutContext.createTempSymbol();
   AP.OutStreamer->EmitLabel(MILabel);
+  User::const_op_iterator Op = nullptr;
 
   LocationVec Locations;
   LiveOutVec LiveOuts;
@@ -292,13 +411,33 @@
   if (recordResult) {
     assert(PatchPointOpers(&MI).hasDef() && "Stackmap has no return value.");
     parseOperand(MI.operands_begin(), std::next(MI.operands_begin()), Locations,
-                 LiveOuts);
+                 LiveOuts, Op);
   }
 
+  // Find the IR stackmap instruction which corresponds to MI so we can emit
+  // type information along with the value's location
+  const BasicBlock *BB = MI.getParent()->getBasicBlock();
+  const IntrinsicInst *IRSM = nullptr;
+  const std::string SMName("llvm.experimental.stackmap");
+  for(auto BBI = BB->begin(), BBE = BB->end(); BBI != BBE; BBI++)
+  {
+    const IntrinsicInst *II;
+    if((II = dyn_cast<IntrinsicInst>(&*BBI)) &&
+       II->getCalledFunction()->getName() == SMName &&
+       cast<ConstantInt>(II->getArgOperand(0))->getZExtValue() == ID)
+    {
+      IRSM = cast<IntrinsicInst>(&*BBI);
+      break;
+    }
+  }
+  assert(IRSM && "Could not find associated stackmap instruction");
+
   // Parse operands.
+  Op = std::next(IRSM->op_begin(), 2);
   while (MOI != MOE) {
-    MOI = parseOperand(MOI, MOE, Locations, LiveOuts);
+    MOI = parseOperand(MOI, MOE, Locations, LiveOuts, Op);
   }
+  assert(Op == (IRSM->op_end() - 1) && "did not lower all stackmap operands");
 
   // Move large constants into the constant pool.
   for (auto &Loc : Locations) {
@@ -327,8 +466,8 @@
       MCSymbolRefExpr::create(MILabel, OutContext),
       MCSymbolRefExpr::create(AP.CurrentFnSymForSize, OutContext), OutContext);
 
-  CSInfos.emplace_back(CSOffsetExpr, ID, std::move(Locations),
-                       std::move(LiveOuts));
+  CSInfos.emplace_back(AP.CurrentFnSym, CSOffsetExpr, ID,
+                       std::move(Locations), std::move(LiveOuts));
 
   // Record the stack size of the current function.
   const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
@@ -417,7 +556,7 @@
   DEBUG(dbgs() << WSMP << "functions:\n");
   for (auto const &FR : FnStackSize) {
     DEBUG(dbgs() << WSMP << "function addr: " << FR.first
-                 << " frame size: " << FR.second);
+                 << " frame size: " << FR.second << "\n");
     OS.EmitSymbolValue(FR.first, 8);
     OS.EmitIntValue(FR.second, 8);
   }
@@ -439,6 +578,8 @@
 ///
 /// StkMapRecord[NumRecords] {
 ///   uint64 : PatchPoint ID
+///   uint32 : Index of Function Stack Size Record
+///   uint32 : Padding
 ///   uint32 : Instruction Offset
 ///   uint16 : Reserved (record flags)
 ///   uint16 : NumLocations
@@ -447,6 +588,11 @@
 ///     uint8  : Size in Bytes
 ///     uint16 : Dwarf RegNum
 ///     int32  : Offset
+///     uint8  : Is it a pointer?
+///     uint8  : Is it an alloca?
+///     uint8  : Is it a duplicate record for the same live value?
+///     uint8  : Padding
+///     uint32 : Size of pointed-to data
 ///   }
 ///   uint16 : Padding
 ///   uint16 : NumLiveOuts
@@ -487,6 +633,8 @@
     }
 
     OS.EmitIntValue(CSI.ID, 8);
+    OS.EmitIntValue(FnStackSize.find(CSI.Func) - FnStackSize.begin(), 4);
+    OS.EmitIntValue(0, 4);
     OS.EmitValue(CSI.CSOffsetExpr, 4);
 
     // Reserved for flags.
@@ -498,6 +646,11 @@
       OS.EmitIntValue(Loc.Size, 1);
       OS.EmitIntValue(Loc.Reg, 2);
       OS.EmitIntValue(Loc.Offset, 4);
+      OS.EmitIntValue(Loc.Ptr, 1);
+      OS.EmitIntValue(Loc.Alloca, 1);
+      OS.EmitIntValue(Loc.Duplicate, 1);
+      OS.EmitIntValue(0, 1);
+      OS.EmitIntValue(Loc.PtrDataSize, 4);
     }
 
     // Num live-out registers and padding to align to 4 byte.
Index: lib/CodeGen/StackSlotColoring.cpp
===================================================================
--- lib/CodeGen/StackSlotColoring.cpp	(revision 277823)
+++ lib/CodeGen/StackSlotColoring.cpp	(working copy)
@@ -278,6 +278,7 @@
   SmallVector<int, 16> SlotMapping(NumObjs, -1);
   SmallVector<float, 16> SlotWeights(NumObjs, 0.0);
   SmallVector<SmallVector<int, 4>, 16> RevMap(NumObjs);
+  SmallDenseMap<int, int, 16> SlotChanges;
   BitVector UsedColors(NumObjs);
 
   DEBUG(dbgs() << "Color spill slot intervals:\n");
@@ -292,7 +293,10 @@
     SlotWeights[NewSS] += li->weight;
     UsedColors.set(NewSS);
     Changed |= (SS != NewSS);
+    if(SS != NewSS) SlotChanges[SS] = NewSS;
   }
+  MF.updateSMStackSlotRefs(SlotChanges);
+  MF.updateSMBackingStackSlotRefs(SlotChanges);
 
   DEBUG(dbgs() << "\nSpill slots after coloring:\n");
   for (unsigned i = 0, e = SSIntervals.size(); i != e; ++i) {
Index: lib/CodeGen/StackTransformMetadata.cpp
===================================================================
--- lib/CodeGen/StackTransformMetadata.cpp	(revision 0)
+++ lib/CodeGen/StackTransformMetadata.cpp	(working copy)
@@ -0,0 +1,595 @@
+//=== llvm/CodeGen/StackTransformMetadata.cpp - Stack Transformation Metadata ===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file accumulates additional data from machine functions needed to do
+// correct and complete stack transformation.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/CodeGen/LiveIntervalAnalysis.h"
+#include "llvm/CodeGen/LiveStackAnalysis.h"
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/Passes.h"
+#include "llvm/CodeGen/VirtRegMap.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/Target/TargetInstrInfo.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "stack-transform-metadata"
+
+//===----------------------------------------------------------------------===//
+//                          StackTransformMetadata
+//===----------------------------------------------------------------------===//
+//
+// Run analyses over machine functions (before virtual register rewriting) to
+// glean additional information about live values.  This analysis finds
+// duplicate locations for live values, including backing stack slots and other
+// registers.
+//
+// TODO this analysis should also find pre-populated registers, e.g., pointers
+// to the argument area
+//
+namespace {
+class StackTransformMetadata : public MachineFunctionPass {
+  MachineFunction *MF;
+  const MachineRegisterInfo *MRI;
+  const TargetInstrInfo *TII;
+  const LiveIntervals *LI;
+  const LiveStacks *LS;
+  const SlotIndexes *Indexes;
+  const VirtRegMap *VRM;
+
+  /// Operation type (copied from StackMap.h, without including everything else)
+  enum OpType { DirectMemRefOp, IndirectMemRefOp, ConstantOp };
+
+  /// A bundle tying together a stackmap IR instruction, the generated stackmap
+  /// machine instruction and the call machine instruction that caused the
+  /// stackmap to be emitted in the IR, respectively
+  typedef std::tuple<const CallInst *,
+                     const MachineInstr *,
+                     const MachineInstr *> SMInstBundle;
+
+  /// Getters for individual elements of instruction bundles
+  static inline const CallInst *getIRSM(const SMInstBundle &B) { return std::get<0>(B); }
+  static inline const MachineInstr *getMISM(const SMInstBundle &B) { return std::get<1>(B); }
+  static inline const MachineInstr *getMICall(const SMInstBundle &B) { return std::get<2>(B); }
+
+  /// Mapping between virtual registers and IR operands
+  typedef std::pair<unsigned, SmallVector<const Value *, 8> > RegValsPair;
+  typedef std::map<unsigned, SmallVector<const Value *, 8> > RegValsMap;
+
+  /// A value's spill location
+  class SpillLoc {
+  public:
+    enum Type { NONE, VREG, STACK_LOAD, STACK_STORE };
+    unsigned Vreg;
+    SpillLoc() : Vreg(VirtRegMap::NO_PHYS_REG) {}
+    SpillLoc(unsigned Vreg) : Vreg(Vreg) {}
+    virtual SpillLoc *copy() const = 0;
+    virtual ~SpillLoc() {}
+    virtual Type getType() const = 0;
+  };
+
+  /// A spill to a stack slot
+  class StackSpillLoc : public SpillLoc {
+  public:
+    int StackSlot;
+    StackSpillLoc() : StackSlot(VirtRegMap::NO_STACK_SLOT) {}
+    StackSpillLoc(unsigned Vreg, int StackSlot) :
+                      SpillLoc(Vreg), StackSlot(StackSlot) {}
+    virtual SpillLoc *copy() const = 0;
+    virtual Type getType() const = 0;
+  };
+
+  /// A load from a stack slot
+  class StackLoadLoc : public StackSpillLoc {
+  public:
+    StackLoadLoc() {}
+    StackLoadLoc(unsigned Vreg, int StackSlot) :
+                     StackSpillLoc(Vreg, StackSlot) {}
+    virtual SpillLoc *copy() const {
+      return new StackLoadLoc(Vreg, StackSlot);
+    }
+    virtual Type getType() const { return SpillLoc::STACK_LOAD; }
+  };
+
+  /// A store to a stack slot
+  class StackStoreLoc : public StackSpillLoc {
+  public:
+    StackStoreLoc() {}
+    StackStoreLoc(unsigned Vreg, int StackSlot) :
+                      StackSpillLoc(Vreg, StackSlot) {}
+    virtual SpillLoc *copy() const {
+      return new StackStoreLoc(Vreg, StackSlot);
+    }
+    virtual Type getType() const { return SpillLoc::STACK_STORE; }
+  };
+
+  /// A spill to another register
+  class RegSpillLoc : public SpillLoc {
+  public:
+    unsigned SrcVreg;
+    RegSpillLoc() : SrcVreg(VirtRegMap::NO_PHYS_REG) {}
+    RegSpillLoc(unsigned DefVreg, unsigned SrcVreg) :
+                    SpillLoc(DefVreg), SrcVreg(SrcVreg) {}
+    virtual SpillLoc *copy() const {
+      return new RegSpillLoc(Vreg, SrcVreg);
+    }
+    virtual Type getType() const { return SpillLoc::VREG; }
+  };
+
+  /// Find stackmap operands that have been spilled to alternate locations
+  void findSpilledStackmapOps();
+
+  /// Gather stackmap machine instructions, the IR instructions which generated
+  /// the stackmaps, and their associated call machine instructions
+  void bundleStackmaps(SmallVector<SMInstBundle, 32> &SM);
+
+  /// Find all virtual register operands in a stackmap and collect virtual
+  /// register/IR value mappings
+  void findVregOps(const CallInst *IRSM,
+                   const MachineInstr *MISM,
+                   RegValsMap &Vregs);
+
+  /// Unwind live value movement in the series of instructions between a call
+  /// and a stackmap
+  void unwindToCall(const SMInstBundle &SM, RegValsMap &Vregs);
+
+  /// Analyze a machine instruction to see if a value is getting restored
+  /// from a spill location.
+  SpillLoc *getSpillLocation(const MachineInstr *MI) const;
+
+  /// Return whether or not a virtual registers is defined within a range of
+  /// machine instructions, inclusive
+  const MachineInstr *definedInRange(const MachineInstr *Start,
+                                     const MachineInstr *End,
+                                     unsigned Vreg) const;
+
+  /// Find if a virtual register is backed by a stack slot
+  int findBackingStackSlots(unsigned Vreg, const MachineInstr *SM);
+public:
+  static char ID;
+  StackTransformMetadata() : MachineFunctionPass(ID) {}
+
+  void getAnalysisUsage(AnalysisUsage &AU) const override;
+
+  bool runOnMachineFunction(MachineFunction&) override;
+};
+} // end anonymous namespace
+
+char &llvm::StackTransformMetadataID = StackTransformMetadata::ID;
+
+INITIALIZE_PASS_BEGIN(StackTransformMetadata, "stacktransformmetadata",
+  "Analyze functions for additional stack transformation metadata", false, true)
+INITIALIZE_PASS_DEPENDENCY(SlotIndexes)
+INITIALIZE_PASS_DEPENDENCY(LiveIntervals)
+INITIALIZE_PASS_DEPENDENCY(LiveStacks)
+INITIALIZE_PASS_DEPENDENCY(VirtRegMap)
+INITIALIZE_PASS_END(StackTransformMetadata, "stacktransformmetadata",
+  "Analyze functions for additional stack transformation metadata", false, true)
+
+char StackTransformMetadata::ID = 0;
+
+void StackTransformMetadata::getAnalysisUsage(AnalysisUsage &AU) const {
+  AU.setPreservesAll();
+  AU.addRequired<LiveIntervals>();
+  AU.addRequired<LiveStacks>();
+  AU.addRequired<SlotIndexes>();
+  AU.addRequired<VirtRegMap>();
+  MachineFunctionPass::getAnalysisUsage(AU);
+}
+
+bool StackTransformMetadata::runOnMachineFunction(MachineFunction &fn) {
+  MF = &fn;
+  TII = MF->getSubtarget().getInstrInfo();
+  MRI = &MF->getRegInfo();
+  Indexes = &getAnalysis<SlotIndexes>();
+  LI = &getAnalysis<LiveIntervals>();
+  LS = &getAnalysis<LiveStacks>();
+  VRM = &getAnalysis<VirtRegMap>();
+
+  if(MF->getFrameInfo()->hasStackMap()) {
+    DEBUG(
+      dbgs() << "\n********** STACK TRANSFORMATION METADATA **********\n"
+             << "********** Function: " << MF->getName() << '\n';
+      VRM->dump();
+    );
+
+    findSpilledStackmapOps();
+
+    // TODO what about duplicate registers & stack slots?
+
+    // TODO find pre-populated registers that do not correspond to live values 
+  }
+
+  return false;
+}
+
+/// Gather stackmap machine instructions, the IR instructions which generated
+/// the stackmaps, and their associated call machine instructions
+void
+StackTransformMetadata::bundleStackmaps(SmallVector<SMInstBundle, 32> &SM) {
+  static const std::string SMName("llvm.experimental.stackmap");
+  for(auto MBB = MF->begin(), MBBE = MF->end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), MIE = MBB->instr_end();
+        MI != MIE;
+        MI++) {
+      if(MI->getOpcode() == TargetOpcode::STACKMAP) {
+        // Find the stackmap IR instruction
+        assert(MI->getOperand(0).isImm() && "Invalid stackmap ID");
+        int64_t ID = MI->getOperand(0).getImm();
+        const BasicBlock *BB = MI->getParent()->getBasicBlock();
+        const CallInst *SMIR = nullptr;
+        for(auto I = BB->begin(), IE = BB->end(); I != IE; I++)
+        {
+          const IntrinsicInst *II;
+          if((II = dyn_cast<IntrinsicInst>(&*I)) &&
+             II->getCalledFunction()->getName() == SMName &&
+             cast<ConstantInt>(II->getArgOperand(0))->getSExtValue() == ID) {
+            SMIR = cast<CallInst>(II);
+            break;
+          }
+        }
+        assert(SMIR && "Could not find stackmap IR instruction");
+
+        // Find the call instruction
+        const MachineInstr *MCI = MI->getPrevNode();
+        while(MCI != nullptr) {
+          if(MCI->isCall()) {
+            if(MCI->getOpcode() == TargetOpcode::STACKMAP)
+              MCI = nullptr;
+            break;
+          }
+          MCI = MCI->getPrevNode();
+        }
+
+        if(!MCI) {
+          DEBUG(
+            dbgs() << "WARNING: stackmap " << ID << " ";
+            SMIR->printAsOperand(dbgs());
+            dbgs() << ": could not find associated call instruction "
+                      "(lowered to a native instruction?)\n";
+          );
+          continue;
+        }
+
+        SM.push_back(SMInstBundle(SMIR, &*MI, MCI));
+      }
+    }
+  }
+}
+
+/// Find all virtual register operands in a stackmap and collect virtual
+/// register/IR value mappings
+void StackTransformMetadata::findVregOps(const CallInst *IRSM,
+                                         const MachineInstr *MISM,
+                                         RegValsMap &Vregs) {
+  RegValsMap::iterator VregIt;
+  MachineInstr::const_mop_iterator MOit;
+  CallInst::const_op_iterator IRit;
+
+  for(MOit = std::next(MISM->operands_begin(), 2),
+      IRit = std::next(IRSM->op_begin(), 2);
+      MOit != MISM->operands_end() && IRit != (IRSM->op_end() - 1);
+      MOit++, IRit++) {
+    // Emulate StackMaps::parseOperand to correlate IR and machine operands
+    if(MOit->isImm()) {
+      switch(MOit->getImm()) {
+      case DirectMemRefOp: MOit++; MOit++; break;
+      case IndirectMemRefOp: MOit++; MOit++; MOit++; break;
+      case ConstantOp: MOit++; break;
+      default: llvm_unreachable("Unrecognized operand type.");
+      }
+    } else if(MOit->isReg()) {
+      const Value *IRVal = IRit->get();
+      unsigned Reg = MOit->getReg();
+
+      assert(IRVal && "Invalid stackmap IR operand");
+      assert(TargetRegisterInfo::isVirtualRegister(Reg) &&
+             "Should not have been converted to physical registers yet");
+
+      DEBUG(
+        IRVal->printAsOperand(dbgs());
+        dbgs() << ": in vreg" << TargetRegisterInfo::virtReg2Index(Reg) << "\n";
+      );
+
+      if((VregIt = Vregs.find(Reg)) == Vregs.end()) {
+        SmallVector<const Value *, 8> vals;
+        VregIt = Vregs.insert(RegValsPair(Reg, std::move(vals))).first;
+      }
+      VregIt->second.push_back(IRVal);
+    }
+  }
+  assert(IRit == (IRSM->op_end() - 1) && "Did not search all stackmap operands");
+}
+
+/// Analyze a machine instruction to see if a value is getting restored from a
+/// spill location.
+StackTransformMetadata::SpillLoc *
+StackTransformMetadata::getSpillLocation(const MachineInstr *MI) const {
+  unsigned SrcVreg;
+  unsigned DefVreg;
+  int SS;
+
+  assert(MI && "Invalid machine instruction");
+
+  // Is it a copy from another register?
+  if(MI->isCopy()) {
+    for(unsigned i = 0, e = MI->getNumOperands(); i != e; i++) {
+      const MachineOperand &MO = MI->getOperand(i);
+      if(MO.isReg()) {
+        if(MO.isDef()) DefVreg = MO.getReg();
+        else SrcVreg = MO.getReg();
+      }
+    }
+
+    if(TargetRegisterInfo::isVirtualRegister(SrcVreg) &&
+       TargetRegisterInfo::isVirtualRegister(DefVreg))
+      return new RegSpillLoc(DefVreg, SrcVreg);
+  }
+
+  // Is it a load from the stack?
+  if((DefVreg = TII->isLoadFromStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(DefVreg))
+      return new StackLoadLoc(DefVreg, SS);
+
+  // Is it a store to the stack?
+  if((SrcVreg = TII->isStoreToStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(SrcVreg))
+      return new StackStoreLoc(SrcVreg, SS);
+
+  // Something else
+  return nullptr;
+}
+
+/// Return whether or not a machine instruction is defined within a range of
+/// machine instructions, inclusive
+const MachineInstr *
+StackTransformMetadata::definedInRange(const MachineInstr *Start,
+                                       const MachineInstr *End,
+                                       unsigned Vreg) const {
+  assert(Start && End && "Invalid machine instruction");
+  assert(TargetRegisterInfo::isVirtualRegister(Vreg) && "Invalid register");
+  assert(Start->getParent() == End->getParent() &&
+         "Range must be contained within the same basic block");
+
+  // Search over all the vreg's definitions
+  for(MachineRegisterInfo::def_instr_iterator DI = MRI->def_instr_begin(Vreg),
+      DIE = MRI->def_instr_end();
+      DI != DIE; DI++) {
+    const MachineInstr *MI = &*DI;
+
+    // Shortcut -- are we the starting or ending instruction of the range?
+    if(MI == Start || MI == End) return MI;
+
+    // Search the range of machine instructions
+    for(const MachineInstr *Cur = Start->getNextNode();
+        Cur != End && Cur != nullptr;
+        Cur = Cur->getNextNode())
+      if(Cur == MI)
+        return MI;
+  }
+
+  // None of the definitions were within the range
+  return nullptr;
+}
+
+/// Unwind live value movement in the series of instructions between a call and
+/// a stackmap
+void StackTransformMetadata::unwindToCall(const SMInstBundle &SM,
+                                          RegValsMap &Vregs) {
+  unsigned PhysReg;
+  const CallInst *IRSM = getIRSM(SM);
+  const MachineInstr *MISM = getMISM(SM), *MICall = getMICall(SM), *Cur;
+  SpillLoc *Loc, *DefChain;
+  StackLoadLoc *SLL;
+  RegSpillLoc *RSL;
+  RegValsMap::iterator vregIt;
+
+  for(Cur = MICall->getNextNode(); Cur != MISM; Cur = Cur->getNextNode()) {
+    Loc = getSpillLocation(Cur);
+    if(!Loc) continue;
+    if((vregIt = Vregs.find(Loc->Vreg)) == Vregs.end()) {
+      delete Loc;
+      continue;
+    }
+
+    // We may be unwinding a chain of copies to find the original spill
+    // location.  There are 2 halting conditions for the while-loop below:
+    //
+    //  1. Restoring the vreg from a spill slot
+    //  2. Restoring the vreg from a callee-saved register allocated to a
+    //     vreg whose definition is NOT between the call and the stackmap
+    //
+    // The second condition is qualified by the location of the definition of
+    // the callee-saved vreg because the backend can generate really stupid
+    // code, e.g., on x86:
+    //
+    //    callq ...
+    //    mov -0x10(%rbp), %rbx
+    //    mov %rbx, %rcx
+    //    <stackmap machine instruction>
+    //
+    // TODO it should not possible to restore from a stack slot, then spill
+    // again before reaching the stackmap -- this would invalidate #1 above.
+    DefChain = Loc->copy();
+    while(DefChain && DefChain->getType() == SpillLoc::VREG) {
+      RSL = (RegSpillLoc *)DefChain;
+      const MachineInstr *Def = definedInRange(MICall, MISM, RSL->SrcVreg);
+
+      // Are we in a callee-saved register defined outside of the range of
+      // instructions between the call and the stackmap?
+      if(!Def && !MF->isCallerSaved(VRM->getPhys(RSL->SrcVreg)))
+          break;
+
+      assert(Def && "Invalid virtual register definition");
+      DefChain = getSpillLocation(Def);
+      delete RSL;
+    }
+
+    if(!DefChain) {
+      delete Loc;
+      continue;
+    }
+
+    switch(DefChain->getType()) {
+    case SpillLoc::VREG:
+      RSL = (RegSpillLoc *)DefChain;
+      PhysReg = VRM->getPhys(RSL->SrcVreg);
+      assert(PhysReg != VirtRegMap::NO_PHYS_REG && "Invalid register");
+      assert(!MF->isCallerSaved(PhysReg) && "Invalid register");
+
+      for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+        DEBUG(
+          vregIt->second[sz]->printAsOperand(dbgs());
+          dbgs() << ": spilled to callee-saved register "
+                 << PrintReg(PhysReg, &VRM->getTargetRegInfo()) << "\n";
+        );
+        MF->addSMOpPhysRegMapping(IRSM, vregIt->second[sz], PhysReg);
+      }
+
+      // We need to check the vreg at the head of the copy chain for spill
+      // locations instead of the vreg in the stackmap
+      Vregs[RSL->SrcVreg] = vregIt->second;
+      Vregs.erase(Loc->Vreg);
+      break;
+    case SpillLoc::STACK_LOAD:
+      SLL = (StackLoadLoc *)DefChain;
+      assert(SLL->StackSlot != VirtRegMap::NO_STACK_SLOT && "Invalid stack slot");
+
+      for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+        DEBUG(
+          vregIt->second[sz]->printAsOperand(dbgs());
+          dbgs() << ": spilled to stack slot " << SLL->StackSlot << "\n";
+        );
+        MF->addSMOpStackSlotMapping(IRSM, vregIt->second[sz], SLL->StackSlot);
+      }
+
+      // Since we've already resolved the vreg to a stack slot, remove the
+      // vreg so we don't try to find backing stack slots
+      Vregs.erase(Loc->Vreg);
+      break;
+    case SpillLoc::STACK_STORE:
+    case SpillLoc::NONE:
+    default:
+      DEBUG(
+        dbgs() << "WARNING: ignoring machine instruction:\n";
+        Cur->dump();
+      );
+      break;
+    }
+
+    delete Loc;
+    delete DefChain;
+  }
+}
+
+/// Find if a virtual register is backed by a stack slot
+int StackTransformMetadata::findBackingStackSlots(unsigned Vreg,
+                                                  const MachineInstr *SM) {
+  int ret = VirtRegMap::NO_STACK_SLOT;
+  SpillLoc *Loc;
+  StackSpillLoc *SSL;
+  SlotIndex SMIdx = Indexes->getInstructionIndex(SM), Use;
+  LiveInterval::const_iterator Seg;
+
+  for(MachineRegisterInfo::reg_instr_iterator MI = MRI->reg_instr_begin(Vreg),
+      MIE = MRI->reg_instr_end();
+      MI != MIE; MI++) {
+    Loc = getSpillLocation(&*MI);
+    if(!Loc) continue;
+
+    switch(Loc->getType()) {
+    case SpillLoc::STACK_LOAD:
+    case SpillLoc::STACK_STORE:
+      // Search for stack loads/stores associated with the vreg, and check if
+      // those stack slots are live at the same time as the stackmap
+      SSL = (StackSpillLoc*)Loc;
+      if(SSL->StackSlot >= 0 && LS->hasInterval(SSL->StackSlot)) {
+        Use = Indexes->getInstructionIndex(&*MI);
+        Seg = LS->getInterval(SSL->StackSlot).find(Use);
+        if(Seg->contains(SMIdx))
+          ret = SSL->StackSlot;
+      } else {
+        DEBUG(
+          dbgs() << "WARNING: ignoring when searching for backing slot:\n";
+          MI->dump();
+        );
+      }
+      break;
+    case SpillLoc::VREG:
+    case SpillLoc::NONE:
+    default: break;
+    }
+    delete Loc;
+  }
+
+  return ret;
+}
+
+/// Find stackmap operands that have been spilled to alternate locations
+void StackTransformMetadata::findSpilledStackmapOps()
+{
+  SmallVector<SMInstBundle, 32> SM;
+  RegValsMap vregs;
+  RegValsMap::iterator vregIt, vregEnd;
+
+  // Gather the stackmaps
+  bundleStackmaps(SM);
+
+  // Iterate over all stackmaps to find virtual register operands which have
+  // been spilled to the stack or to other registers
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++) {
+    const CallInst *IRSM = getIRSM(*S);
+    const MachineInstr *MISM = getMISM(*S);
+
+    DEBUG(
+      const MachineInstr *MICall = getMICall(*S);
+      dbgs() << "\nStackmap " << MISM->getOperand(0).getImm() << ":\n";
+      MISM->dump();
+      dbgs() << "\nInstructions between call and stackmap:\n";
+      while(MICall != MISM) {
+        MICall->dump();
+        MICall = MICall->getNextNode();
+      }
+      dbgs() << '\n';
+    );
+
+    // Get all virtual register operands in the stackmap
+    findVregOps(IRSM, MISM, vregs);
+
+    // Walk from the call to the stackmap, reversing stackmap operand movement
+    unwindToCall(*S, vregs);
+
+    // Walk through remaining virtual register operands to see if they have a
+    // backing stack slot
+    for(vregIt = vregs.begin(), vregEnd = vregs.end();
+        vregIt != vregEnd;
+        vregIt++) {
+      int StackSlot = findBackingStackSlots(vregIt->first, MISM);
+      if(StackSlot != VirtRegMap::NO_STACK_SLOT) {
+        for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+          DEBUG(
+            vregIt->second[sz]->printAsOperand(dbgs());
+            dbgs() << ": backed by stack slot " << StackSlot << "\n"
+          );
+          MF->addSMOpBackingStackSlot(IRSM, vregIt->second[sz], StackSlot);
+        }
+      }
+    }
+
+    vregs.clear();
+  }
+}
+
Index: lib/Target/AArch64/AArch64AsmPrinter.cpp
===================================================================
--- lib/Target/AArch64/AArch64AsmPrinter.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64AsmPrinter.cpp	(working copy)
@@ -129,8 +129,8 @@
     // linker can safely perform dead code stripping.  Since LLVM never
     // generates code that does this, it is always safe to set.
     OutStreamer->EmitAssemblerFlag(MCAF_SubsectionsViaSymbols);
-    SM.serializeToStackMapSection();
   }
+  SM.serializeToStackMapSection();
 }
 
 MachineLocation
Index: lib/Target/X86/X86AsmPrinter.cpp
===================================================================
--- lib/Target/X86/X86AsmPrinter.cpp	(revision 277823)
+++ lib/Target/X86/X86AsmPrinter.cpp	(working copy)
@@ -49,6 +49,8 @@
 bool X86AsmPrinter::runOnMachineFunction(MachineFunction &MF) {
   Subtarget = &MF.getSubtarget<X86Subtarget>();
 
+  bool modified = TagCallSites(MF);
+
   SMShadowTracker.startFunction(MF);
 
   SetupMachineFunction(MF);
@@ -66,8 +68,8 @@
   // Emit the rest of the function body.
   EmitFunctionBody();
 
-  // We didn't modify anything.
-  return false;
+  // We may have modified where stack map intrinsics are located.
+  return modified;
 }
 
 /// printSymbolOperand - Print a raw symbol reference operand.  This handles
