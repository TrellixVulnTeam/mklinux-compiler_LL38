Index: include/llvm/ADT/ilist_node.h
===================================================================
--- include/llvm/ADT/ilist_node.h	(revision 277823)
+++ include/llvm/ADT/ilist_node.h	(working copy)
@@ -70,7 +70,7 @@
     const NodeTy *Prev = this->getPrev();
 
     // Check for sentinel.
-    if (!Prev->getNext())
+    if (!Prev || !Prev->getNext())
       return nullptr;
 
     return Prev;
@@ -81,7 +81,7 @@
     NodeTy *Next = getNext();
 
     // Check for sentinel.
-    if (!Next->getNext())
+    if (!Next || !Next->getNext())
       return nullptr;
 
     return Next;
Index: include/llvm/CodeGen/AsmPrinter.h
===================================================================
--- include/llvm/CodeGen/AsmPrinter.h	(revision 277823)
+++ include/llvm/CodeGen/AsmPrinter.h	(working copy)
@@ -199,9 +199,10 @@
 
   /// Emit the specified function out to the OutStreamer.
   bool runOnMachineFunction(MachineFunction &MF) override {
+    bool modified = TagCallSites(MF);
     SetupMachineFunction(MF);
     EmitFunctionBody();
-    return false;
+    return modified;
   }
 
   //===------------------------------------------------------------------===//
@@ -329,6 +330,10 @@
   /// instructions in verbose mode.
   virtual void emitImplicitDef(const MachineInstr *MI) const;
 
+  /// Offset to adjust values returned by getObjectOffset to be an offset from
+  /// the function's frame base pointer
+  virtual unsigned getFBPOffset(void) { return 16; }
+
   //===------------------------------------------------------------------===//
   // Symbol Lowering Routines.
   //===------------------------------------------------------------------===//
@@ -393,6 +398,14 @@
     EmitLabelPlusOffset(Label, 0, Size, IsSectionRelative);
   }
 
+  /// Find the stackmap intrinsic associated with a function call
+  MachineInstr *FindStackMap(MachineBasicBlock &MBB,
+                             MachineInstr *MI) const;
+
+  /// Move stackmap intrinsics directly after calls to correctly capture
+  /// return addresses
+  bool TagCallSites(MachineFunction &MF);
+
   //===------------------------------------------------------------------===//
   // Dwarf Emission Helper Routines
   //===------------------------------------------------------------------===//
Index: include/llvm/CodeGen/MachineFunction.h
===================================================================
--- include/llvm/CodeGen/MachineFunction.h	(revision 277823)
+++ include/llvm/CodeGen/MachineFunction.h	(working copy)
@@ -20,6 +20,7 @@
 
 #include "llvm/ADT/ilist.h"
 #include "llvm/CodeGen/MachineBasicBlock.h"
+#include "llvm/IR/Instructions.h"
 #include "llvm/IR/DebugLoc.h"
 #include "llvm/IR/Metadata.h"
 #include "llvm/Support/Allocator.h"
@@ -84,6 +85,18 @@
 };
 
 class MachineFunction {
+  // Mappings between IR values and stack slots
+  typedef DenseMap<const Value*, int> ValStackSlotMap;
+  typedef std::pair<const Value*, int> ValStackSlotPair;
+  typedef DenseMap<const Instruction*, ValStackSlotMap> InstOpStackSlotMap;
+  typedef std::pair<const Instruction*, ValStackSlotMap> InstOpStackSlotPair;
+
+  // Mappings between IR values and physical registers
+  typedef DenseMap<const Value*, unsigned> ValPhysRegMap;
+  typedef std::pair<const Value*, unsigned> ValPhysRegPair;
+  typedef DenseMap<const Instruction*, ValPhysRegMap> InstOpPhysRegMap;
+  typedef std::pair<const Instruction*, ValPhysRegMap> InstOpPhysRegPair;
+
   const Function *Fn;
   const TargetMachine &Target;
   const TargetSubtargetInfo *STI;
@@ -145,6 +158,23 @@
   /// True if the function includes any inline assembly.
   bool HasInlineAsm;
 
+  /// Map from stackmap operands to spilled stack slots
+  InstOpStackSlotMap SMOp2StackSlot;
+
+  /// Map from stackmap operands to physical registers
+  InstOpPhysRegMap SMOp2PhysReg;
+
+  // TODO the next two maps should actually contain sets of backing slots &
+  // duplicate physical registers rather than being restricted to one of each
+
+  /// Map from stackmap operands to spilled stack slots, for operands in
+  /// physical registers that have a backing stack slot
+  InstOpStackSlotMap SMOp2BackingStackSlot;
+
+  /// Map from stackmap operands to physical registers, for operands that
+  /// are duplicated across several registers
+  InstOpPhysRegMap SMOp2DupPhysReg;
+
   MachineFunction(const MachineFunction &) = delete;
   void operator=(const MachineFunction&) = delete;
 public:
@@ -457,6 +487,9 @@
     return Mask;
   }
 
+  /// Is a register caller-saved?
+  bool isCallerSaved(unsigned Reg) const;
+
   /// allocateMemRefsArray - Allocate an array to hold MachineMemOperand
   /// pointers.  This array is owned by the MachineFunction.
   MachineInstr::mmo_iterator allocateMemRefsArray(unsigned long Num);
@@ -488,6 +521,55 @@
   /// getPICBaseSymbol - Return a function-local symbol to represent the PIC
   /// base.
   MCSymbol *getPICBaseSymbol() const;
+
+  //===--------------------------------------------------------------------===//
+  // StackMap IR/physical location mappings
+  //
+
+  /// Add an IR/stack slot mapping for a stackmap operand
+  void addSMOpStackSlotMapping(const CallInst *SM, const Value *Val, int SS);
+  void addSMOpStackSlotMapping(const CallInst *SM, unsigned Op, int SS);
+
+  /// Update stack slot references to new indexes after stack slot coloring
+  void updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes);
+
+  /// Return the stack slot mapped to a stackmap operand
+  int getSMStackSlot(const CallInst *SM, const Value *Val) const;
+  int getSMStackSlot(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/physical register mapping for a stackmap operand
+  void addSMOpPhysRegMapping(const CallInst *SM, const Value *Val, unsigned Reg);
+  void addSMOpPhysRegMapping(const CallInst *SM, unsigned Op, unsigned Reg);
+
+  /// Return the physical register mapped to a stackmap operand
+  unsigned getSMPhysReg(const CallInst *SM, const Value *Val) const;
+  unsigned getSMPhysReg(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/stack slot mapping for a stackmap operand in a physical
+  /// register with a backing stack slot
+  void addSMOpBackingStackSlot(const CallInst *SM, const Value *Val, int SS);
+  void addSMOpBackingStackSlot(const CallInst *SM, unsigned Op, int SS);
+
+  /// Update stack slot references to new indexes after stack slot coloring
+  void updateSMBackingStackSlotRefs(SmallDenseMap<int, int, 16> &Changes);
+
+  // TODO should return a set of backing stack slots
+
+  /// Return the backing stack slot for a stackmap operand mapped to a physical
+  /// register
+  int getSMBackingStackSlot(const CallInst *SM, const Value *Val) const;
+  int getSMBackingStackSlot(const CallInst *SM, unsigned Op) const;
+
+  /// Add an IR/physical register mapping for a stackmap operand with duplicate
+  /// physical registers
+  void addSMOpDupPhysRegMapping(const CallInst *SM, const Value *Val, unsigned Reg);
+  void addSMOpDupPhysRegMapping(const CallInst *SM, unsigned Op, unsigned Reg);
+
+  // TODO should return a set of duplicate registers
+
+  /// Return the duplicate physical register mapped to a stackmap operand
+  unsigned getSMDupPhysReg(const CallInst *SM, const Value *Val) const;
+  unsigned getSMDupPhysReg(const CallInst *SM, unsigned Op) const;
 };
 
 //===--------------------------------------------------------------------===//
Index: include/llvm/CodeGen/Passes.h
===================================================================
--- include/llvm/CodeGen/Passes.h	(revision 277823)
+++ include/llvm/CodeGen/Passes.h	(working copy)
@@ -448,6 +448,10 @@
   // instruction and update the MachineFunctionInfo with that information.
   extern char &ShrinkWrapID;
 
+  /// Stack transformation metadata pass.  Gather additional stack
+  /// transformation metadata from machine functions.
+  extern char &StackTransformMetadataID;
+
   /// VirtRegRewriter pass. Rewrite virtual registers to physical registers as
   /// assigned in VirtRegMap.
   extern char &VirtRegRewriterID;
Index: include/llvm/CodeGen/StackMaps.h
===================================================================
--- include/llvm/CodeGen/StackMaps.h	(revision 277823)
+++ include/llvm/CodeGen/StackMaps.h	(working copy)
@@ -22,6 +22,7 @@
 class AsmPrinter;
 class MCExpr;
 class MCStreamer;
+class UnwindInfo;
 
 /// \brief MI-level patchpoint operands.
 ///
@@ -142,9 +143,16 @@
     unsigned Size;
     unsigned Reg;
     int64_t Offset;
-    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0) {}
-    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset)
-        : Type(Type), Size(Size), Reg(Reg), Offset(Offset) {}
+    bool Ptr;
+    bool Alloca;
+    bool Duplicate;
+    unsigned PtrDataSize;
+    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0),
+                 Ptr(false), Alloca(false), Duplicate(false), PtrDataSize(0) {}
+    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset,
+             bool Ptr, bool Alloca, bool Duplicate, unsigned PtrDataSize)
+        : Type(Type), Size(Size), Reg(Reg), Offset(Offset), Ptr(Ptr),
+          Alloca(Alloca), Duplicate(Duplicate), PtrDataSize(PtrDataSize) {}
   };
 
   struct LiveOutReg {
@@ -171,6 +179,10 @@
     FnStackSize.clear();
   }
 
+  /// Go up the super-register chain until we hit a valid dwarf register
+  /// number.
+  static unsigned getDwarfRegNum(unsigned Reg, const TargetRegisterInfo *TRI);
+
   /// \brief Generate a stackmap record for a stackmap instruction.
   ///
   /// MI must be a raw STACKMAP, not a PATCHPOINT.
@@ -185,7 +197,7 @@
   /// If there is any stack map data, create a stack map section and serialize
   /// the map info into it. This clears the stack map data structures
   /// afterwards.
-  void serializeToStackMapSection();
+  void serializeToStackMapSection(const UnwindInfo *UI = nullptr);
 
 private:
   static const char *WSMP;
@@ -195,15 +207,17 @@
   typedef MapVector<const MCSymbol *, uint64_t> FnStackSizeMap;
 
   struct CallsiteInfo {
+    const MCSymbol *Func;
     const MCExpr *CSOffsetExpr;
     uint64_t ID;
     LocationVec Locations;
     LiveOutVec LiveOuts;
-    CallsiteInfo() : CSOffsetExpr(nullptr), ID(0) {}
-    CallsiteInfo(const MCExpr *CSOffsetExpr, uint64_t ID,
-                 LocationVec &&Locations, LiveOutVec &&LiveOuts)
-        : CSOffsetExpr(CSOffsetExpr), ID(ID), Locations(std::move(Locations)),
-          LiveOuts(std::move(LiveOuts)) {}
+    CallsiteInfo() : Func(nullptr), CSOffsetExpr(nullptr), ID(0) {}
+    CallsiteInfo(const MCSymbol *Func, const MCExpr *CSOffsetExpr,
+                 uint64_t ID, LocationVec &&Locations,
+                 LiveOutVec &&LiveOuts)
+        : Func(Func), CSOffsetExpr(CSOffsetExpr), ID(ID),
+          Locations(std::move(Locations)), LiveOuts(std::move(LiveOuts)) {}
   };
 
   typedef std::vector<CallsiteInfo> CallsiteInfoList;
@@ -213,10 +227,14 @@
   ConstantPool ConstPool;
   FnStackSizeMap FnStackSize;
 
+  /// Get pointer information for stackmap operand
+  void getPointerInfo(const Value *Op, const DataLayout &DL, bool &isPtr,
+                      bool &isAlloca, unsigned &PtrDataSize) const;
+
   MachineInstr::const_mop_iterator
   parseOperand(MachineInstr::const_mop_iterator MOI,
                MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-               LiveOutVec &LiveOuts) const;
+               LiveOutVec &LiveOuts, User::const_op_iterator &Op) const;
 
   /// \brief Create a live-out register record for the given register @p Reg.
   LiveOutReg createLiveOutReg(unsigned Reg,
@@ -240,7 +258,7 @@
   void emitStackmapHeader(MCStreamer &OS);
 
   /// \brief Emit the function frame record for each function.
-  void emitFunctionFrameRecords(MCStreamer &OS);
+  void emitFunctionFrameRecords(MCStreamer &OS, const UnwindInfo *UI);
 
   /// \brief Emit the constant pool.
   void emitConstantPoolEntries(MCStreamer &OS);
Index: include/llvm/CodeGen/UnwindInfo.h
===================================================================
--- include/llvm/CodeGen/UnwindInfo.h	(nonexistent)
+++ include/llvm/CodeGen/UnwindInfo.h	(working copy)
@@ -0,0 +1,111 @@
+//===----------------- UnwindInfo.h - UnwindInfo ---------------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// Generate unwinding information for stack transformation runtime.  Note that
+// this is implemented assuming the function uses a frame base pointer (FBP).
+// This requirement is guaranteed to be satisfied if the function has a
+// stackmap, which are the only functions for which we want to generate
+// unwinding information.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef LLVM_CODEGEN_UNWINDINFO_H
+#define LLVM_CODEGEN_UNWINDINFO_H
+
+#include "llvm/CodeGen/AsmPrinter.h"
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/Support/Debug.h"
+#include <map>
+
+namespace llvm {
+
+class UnwindInfo {
+public:
+  /// Per-function unwinding metadata classes & typedefs
+  class FuncUnwindInfo {
+  public:
+    uint32_t SecOffset; // Offset into unwinding record section
+    uint32_t NumUnwindRecord; // Number of unwinding records
+
+    FuncUnwindInfo() : SecOffset(UINT32_MAX), NumUnwindRecord(0) {}
+    FuncUnwindInfo(uint32_t SecOffset, uint32_t NumUnwindRecord)
+      : SecOffset(SecOffset), NumUnwindRecord(NumUnwindRecord) {}
+  };
+
+  typedef std::pair<const MCSymbol *, FuncUnwindInfo> FuncUnwindPair;
+  typedef std::map<const MCSymbol *, FuncUnwindInfo> FuncUnwindMap;
+
+  /// Unwinding record classes & typedefs
+  class RegOffset {
+  public:
+    uint32_t DwarfReg;
+    int32_t Offset;
+
+    RegOffset() : DwarfReg(0), Offset(0) {}
+    RegOffset(uint32_t DwarfReg, int32_t Offset) :
+      DwarfReg(DwarfReg), Offset(Offset) {}
+  };
+
+  typedef SmallVector<RegOffset, 32> CalleeSavedRegisters;
+  typedef std::pair<const MCSymbol *, CalleeSavedRegisters> FuncCalleePair;
+  typedef std::map<const MCSymbol *, CalleeSavedRegisters> FuncCalleeMap;
+
+  /// \brief Constructors
+  UnwindInfo() = delete;
+  UnwindInfo(AsmPrinter &AP)
+    : AP(AP), OutContext(AP.OutStreamer->getContext()), Emitted(false) {};
+
+  /// \bried Clear all saved unwinding information
+  void reset() {
+    FuncCalleeSaved.clear();
+    FuncUnwindMetadata.clear();
+  }
+
+  /// \brief Store unwinding information for a function
+  void recordUnwindInfo(const MachineFunction &MF);
+
+  /// \brief Add a register restore offset for a function.  MachineReg will get
+  /// converted to a DWARF register internally.
+  void addRegisterUnwindInfo(const MachineFunction &MF,
+                             uint32_t MachineReg,
+                             int32_t Offset);
+
+  /// Create an unwinding information section and serialize the map info into
+  /// it.
+  ///
+  /// Note: unlike StackMaps::serializeToStackMapSection, this function *does
+  /// not* clear out the data structures.  This is so that the stack map
+  /// machinery can access per-function unwinding information.
+  void serializeToUnwindInfoSection();
+
+  /// Get unwinding section metadata for a function
+  const FuncUnwindInfo &getUnwindInfo(const MCSymbol *Func) const;
+
+private:
+  AsmPrinter &AP;
+  MCContext &OutContext;
+  FuncCalleeMap FuncCalleeSaved;
+  FuncUnwindMap FuncUnwindMetadata;
+  bool Emitted;
+
+  /// \brief Emit the unwind info for each function.
+  void emitUnwindInfo(MCStreamer &OS);
+
+  /// \brief Emit the address range info for each function.
+  void emitAddrRangeInfo(MCStreamer &OS);
+
+  void print(raw_ostream &OS);
+  void debug() { print(dbgs()); }
+};
+}
+
+#endif
Index: include/llvm/InitializePasses.h
===================================================================
--- include/llvm/InitializePasses.h	(revision 277823)
+++ include/llvm/InitializePasses.h	(working copy)
@@ -263,6 +263,7 @@
 void initializeStackProtectorPass(PassRegistry&);
 void initializeStackColoringPass(PassRegistry&);
 void initializeStackSlotColoringPass(PassRegistry&);
+void initializeStackTransformMetadataPass(PassRegistry&);
 void initializeStraightLineStrengthReducePass(PassRegistry &);
 void initializeStripDeadDebugInfoPass(PassRegistry&);
 void initializeStripDeadPrototypesPassPass(PassRegistry&);
Index: include/llvm/MC/MCObjectFileInfo.h
===================================================================
--- include/llvm/MC/MCObjectFileInfo.h	(revision 277823)
+++ include/llvm/MC/MCObjectFileInfo.h	(working copy)
@@ -135,6 +135,10 @@
   /// Null if this target doesn't support a BSS section. ELF and MachO only.
   MCSection *TLSBSSSection; // Defaults to ".tbss".
 
+  /// Unwinding address ranges & register location sections.
+  MCSection *UnwindAddrRangeSection;
+  MCSection *UnwindInfoSection;
+
   /// StackMap section.
   MCSection *StackMapSection;
 
@@ -267,6 +271,8 @@
   const MCSection *getTLSDataSection() const { return TLSDataSection; }
   MCSection *getTLSBSSSection() const { return TLSBSSSection; }
 
+  MCSection *getUnwindInfoSection() const { return UnwindInfoSection; }
+  MCSection *getUnwindAddrRangeSection() const { return UnwindAddrRangeSection; }
   MCSection *getStackMapSection() const { return StackMapSection; }
   MCSection *getFaultMapSection() const { return FaultMapSection; }
 
Index: lib/CodeGen/AsmPrinter/AsmPrinter.cpp
===================================================================
--- lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(revision 277823)
+++ lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(working copy)
@@ -1160,6 +1160,41 @@
   return CurExceptionSym;
 }
 
+MachineInstr *AsmPrinter::FindStackMap(MachineBasicBlock &MBB,
+                                       MachineInstr *MI) const {
+  MachineBasicBlock::instr_iterator i, ie;
+  for(i = MI->getNextNode(), ie = MBB.instr_end();
+      i != ie;
+      i = i->getNextNode()) {
+    if(i->getOpcode() == TargetOpcode::STACKMAP)
+      return &*i;
+    else if(i->isCall())
+      break;
+  }
+
+  // Call site without a stackmap implies that either the call was generated by
+  // the backend or the LLVM bitcode was never instrumented by the StackInfo
+  // pass.  This is not necessarily an error!
+  return nullptr;
+}
+
+bool AsmPrinter::TagCallSites(MachineFunction &MF) {
+  bool tagged = false;
+  for(auto MBB = MF.begin(), MBBE = MF.end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), MIE = MBB->instr_end(); MI != MIE; MI++) {
+      if(MI->isCall() && !MI->isPseudo()) {
+        MachineInstr *SMI = FindStackMap(*MBB, &*MI);
+        if(SMI != nullptr) {
+          MBB->remove(SMI);
+          MI = MBB->insert(++MI, SMI);
+          tagged = true;
+        }
+      }
+    }
+  }
+  return tagged;
+}
+
 void AsmPrinter::SetupMachineFunction(MachineFunction &MF) {
   this->MF = &MF;
   // Get the function symbol.
Index: lib/CodeGen/CMakeLists.txt
===================================================================
--- lib/CodeGen/CMakeLists.txt	(revision 277823)
+++ lib/CodeGen/CMakeLists.txt	(working copy)
@@ -111,6 +111,7 @@
   StackSlotColoring.cpp
   StackMapLivenessAnalysis.cpp
   StackMaps.cpp
+  StackTransformMetadata.cpp
   StatepointExampleGC.cpp
   TailDuplication.cpp
   TargetFrameLoweringImpl.cpp
@@ -122,6 +123,7 @@
   TargetSchedule.cpp
   TwoAddressInstructionPass.cpp
   UnreachableBlockElim.cpp
+  UnwindInfo.cpp
   VirtRegMap.cpp
   WinEHPrepare.cpp
 
Index: lib/CodeGen/CodeGen.cpp
===================================================================
--- lib/CodeGen/CodeGen.cpp	(revision 277823)
+++ lib/CodeGen/CodeGen.cpp	(working copy)
@@ -68,6 +68,7 @@
   initializeStackMapLivenessPass(Registry);
   initializeStackProtectorPass(Registry);
   initializeStackSlotColoringPass(Registry);
+  initializeStackTransformMetadataPass(Registry);
   initializeTailDuplicatePassPass(Registry);
   initializeTargetPassConfigPass(Registry);
   initializeTwoAddressInstructionPassPass(Registry);
Index: lib/CodeGen/MachineFunction.cpp
===================================================================
--- lib/CodeGen/MachineFunction.cpp	(revision 277823)
+++ lib/CodeGen/MachineFunction.cpp	(working copy)
@@ -253,6 +253,15 @@
                                MMO->getBaseAlignment());
 }
 
+/// Is a register caller-saved?
+bool MachineFunction::isCallerSaved(unsigned Reg) const {
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+  CallingConv::ID CC = Fn->getCallingConv();
+  const uint32_t *Mask =
+    RegInfo->getTargetRegisterInfo()->getCallPreservedMask(*this, CC);
+  return !((Mask[Reg / 32] >> Reg % 32) & 1);
+}
+
 MachineInstr::mmo_iterator
 MachineFunction::allocateMemRefsArray(unsigned long Num) {
   return Allocator.Allocate<MachineMemOperand *>(Num);
@@ -482,6 +491,281 @@
                                Twine(getFunctionNumber()) + "$pb");
 }
 
+/// Add an IR/stack slot mapping for a stackmap operand
+void MachineFunction::addSMOpStackSlotMapping(const CallInst *SM,
+                                              const Value *Val,
+                                              int SS) {
+  InstOpStackSlotMap::iterator it;
+  std::pair<InstOpStackSlotMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(FrameInfo->getObjectIndexBegin() <= SS &&
+         SS < FrameInfo->getObjectIndexEnd() &&
+         !FrameInfo->isDeadObjectIndex(SS) &&
+         "Invalid stack slot");
+
+  if((it = SMOp2StackSlot.find(SM)) == SMOp2StackSlot.end())
+  {
+    ValStackSlotMap NewMap;
+    ins = SMOp2StackSlot.insert(InstOpStackSlotPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+  it->second.insert(ValStackSlotPair(Val, SS));
+}
+
+void MachineFunction::addSMOpStackSlotMapping(const CallInst *SM,
+                                              unsigned Op,
+                                              int SS) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpStackSlotMapping(SM, SM->getArgOperand(Op), SS);
+}
+
+/// Update stack slot references to new indexes after stack slot coloring
+void
+MachineFunction::updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes) {
+  if(Changes.size()) {
+    DEBUG(dbgs() << "Updating stackmap stack slot references\n";);
+
+    // Iterate over all stackmaps
+    InstOpStackSlotMap::iterator i, ie;
+    for(i = SMOp2StackSlot.begin(), ie = SMOp2StackSlot.end(); i != ie; i++) {
+      // Iterate over all operand/stack slot mappings
+      ValStackSlotMap &Map = i->second;
+      ValStackSlotMap::iterator j, je;
+      for(j = Map.begin(), je = Map.end(); j != je; j++) {
+        SmallDenseMap<int, int, 16>::iterator it;
+        if((it = Changes.find(j->second)) != Changes.end()) {
+          DEBUG(
+            j->first->printAsOperand(dbgs());
+            dbgs() << ": from stack slot " << j->second << " to "
+                   << it->second << "\n";
+          );
+          j->second = it->second;
+        }
+      }
+    }
+  }
+}
+
+/// Return the stack slot mapped to a stackmap operand
+int MachineFunction::getSMStackSlot(const CallInst *SM,
+                                    const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpStackSlotMap::const_iterator i = SMOp2StackSlot.find(SM);
+  if(i != SMOp2StackSlot.end())
+  {
+    ValStackSlotMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return INT_MAX;
+}
+
+int MachineFunction::getSMStackSlot(const CallInst *SM, unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMStackSlot(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/physical register mapping for a stackmap operand
+void MachineFunction::addSMOpPhysRegMapping(const CallInst *SM,
+                                            const Value *Val,
+                                            unsigned Reg) {
+  InstOpPhysRegMap::iterator it;
+  std::pair<InstOpPhysRegMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+
+  if((it = SMOp2PhysReg.find(SM)) == SMOp2PhysReg.end())
+  {
+    ValPhysRegMap NewMap;
+    ins = SMOp2PhysReg.insert(InstOpPhysRegPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+  it->second.insert(ValPhysRegPair(Val, Reg));
+}
+
+void MachineFunction::addSMOpPhysRegMapping(const CallInst *SM,
+                                            unsigned Op,
+                                            unsigned Reg) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpPhysRegMapping(SM, SM->getArgOperand(Op), Reg);
+}
+
+/// Return the physical register mapped to a stackmap operand
+unsigned MachineFunction::getSMPhysReg(const CallInst *SM,
+                                       const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpPhysRegMap::const_iterator i = SMOp2PhysReg.find(SM);
+  if(i != SMOp2PhysReg.end())
+  {
+    ValPhysRegMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return UINT_MAX;
+}
+
+unsigned MachineFunction::getSMPhysReg(const CallInst *SM,
+                                       unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMPhysReg(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/stack slot mapping for a stackmap operand in a physical register
+/// with a backing stack slot
+void MachineFunction::addSMOpBackingStackSlot(const CallInst *SM,
+                                              const Value *Val,
+                                              int SS) {
+  InstOpStackSlotMap::iterator it;
+  std::pair<InstOpStackSlotMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(FrameInfo->getObjectIndexBegin() <= SS &&
+         SS < FrameInfo->getObjectIndexEnd() &&
+         !FrameInfo->isDeadObjectIndex(SS) &&
+         "Invalid stack slot");
+
+  if((it = SMOp2BackingStackSlot.find(SM)) == SMOp2BackingStackSlot.end())
+  {
+    ValStackSlotMap NewMap;
+    ins = SMOp2BackingStackSlot.insert(InstOpStackSlotPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+
+  // TODO allow multiple backing slots
+  ValStackSlotMap::iterator valIt = it->second.find(Val);
+  if(valIt == it->second.end()) it->second.insert(ValStackSlotPair(Val, SS));
+  else assert(valIt->second == SS && "Multiple backing slots");
+}
+
+void MachineFunction::addSMOpBackingStackSlot(const CallInst *SM,
+                                           unsigned Op,
+                                           int SS) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpBackingStackSlot(SM, SM->getArgOperand(Op), SS);
+}
+
+/// Update stack slot references to new indexes after stack slot coloring
+void MachineFunction::updateSMBackingStackSlotRefs(SmallDenseMap<int,
+                                                              int,
+                                                              16> &Changes) {
+  if(Changes.size()) {
+    DEBUG(dbgs() << "Updating stackmap backing stack slot references\n";);
+
+    // Iterate over all stackmaps
+    InstOpStackSlotMap::iterator i, ie;
+    for(i = SMOp2BackingStackSlot.begin(), ie = SMOp2BackingStackSlot.end();
+        i != ie;
+        i++) {
+      // Iterate over all operand/stack slot mappings
+      ValStackSlotMap &Map = i->second;
+      ValStackSlotMap::iterator j, je;
+      for(j = Map.begin(), je = Map.end(); j != je; j++) {
+        SmallDenseMap<int, int, 16>::iterator it;
+        if((it = Changes.find(j->second)) != Changes.end()) {
+          DEBUG(
+            j->first->printAsOperand(dbgs());
+            dbgs() << ": from stack slot " << j->second << " to "
+                   << it->second << "\n";
+          );
+          j->second = it->second;
+        }
+      }
+    }
+  }
+}
+
+/// Return the backing stack slot for a stackmap operand mapped to a physical
+/// register
+int MachineFunction::getSMBackingStackSlot(const CallInst *SM,
+                                        const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpStackSlotMap::const_iterator i = SMOp2BackingStackSlot.find(SM);
+  if(i != SMOp2BackingStackSlot.end())
+  {
+    ValStackSlotMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return INT_MAX;
+}
+
+int MachineFunction::getSMBackingStackSlot(const CallInst *SM, unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMBackingStackSlot(SM, SM->getArgOperand(Op));
+}
+
+/// Add an IR/physical register mapping for a stackmap operand
+void MachineFunction::addSMOpDupPhysRegMapping(const CallInst *SM,
+                                               const Value *Val,
+                                               unsigned Reg) {
+  InstOpPhysRegMap::iterator it;
+  std::pair<InstOpPhysRegMap::iterator, bool> ins;
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+
+  if((it = SMOp2DupPhysReg.find(SM)) == SMOp2DupPhysReg.end())
+  {
+    ValPhysRegMap NewMap;
+    ins = SMOp2DupPhysReg.insert(InstOpPhysRegPair(SM, std::move(NewMap)));
+    assert(ins.second && "Map insertion error");
+    it = ins.first;
+  }
+
+  // TODO allow multiple duplicate registers
+  ValPhysRegMap::iterator valIt = it->second.find(Val);
+  if(valIt == it->second.end()) it->second.insert(ValStackSlotPair(Val, Reg));
+  else assert(valIt->second == Reg && "Multiple duplicate registers");
+}
+
+void MachineFunction::addSMOpDupPhysRegMapping(const CallInst *SM,
+                                               unsigned Op,
+                                               unsigned Reg) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpDupPhysRegMapping(SM, SM->getArgOperand(Op), Reg);
+}
+
+/// Return the physical register mapped to a stackmap operand
+unsigned MachineFunction::getSMDupPhysReg(const CallInst *SM,
+                                          const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid operand");
+
+  InstOpPhysRegMap::const_iterator i = SMOp2DupPhysReg.find(SM);
+  if(i != SMOp2DupPhysReg.end())
+  {
+    ValPhysRegMap::const_iterator j = i->second.find(Val);
+    if(j != i->second.end()) return j->second;
+  }
+  return UINT_MAX;
+}
+
+unsigned MachineFunction::getSMDupPhysReg(const CallInst *SM,
+                                          unsigned Op) const {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  return getSMDupPhysReg(SM, SM->getArgOperand(Op));
+}
+
 //===----------------------------------------------------------------------===//
 //  MachineFrameInfo implementation
 //===----------------------------------------------------------------------===//
Index: lib/CodeGen/Passes.cpp
===================================================================
--- lib/CodeGen/Passes.cpp	(revision 277823)
+++ lib/CodeGen/Passes.cpp	(working copy)
@@ -754,6 +754,10 @@
   // Allow targets to change the register assignments before rewriting.
   addPreRewrite();
 
+  // Gather additional stack transformation metadata before rewriting virtual
+  // registers
+  addPass(&StackTransformMetadataID);
+
   // Finally rewrite virtual registers.
   addPass(&VirtRegRewriterID);
 
Index: lib/CodeGen/RegAllocFast.cpp
===================================================================
--- lib/CodeGen/RegAllocFast.cpp	(revision 277823)
+++ lib/CodeGen/RegAllocFast.cpp	(working copy)
@@ -1078,6 +1078,12 @@
 /// runOnMachineFunction - Register allocate the whole function
 ///
 bool RAFast::runOnMachineFunction(MachineFunction &Fn) {
+  // TODO the fast register allocator behaves poorly for stackmaps with lots
+  // of operands, and since it doesn't use the VirtRegRewriter pass we can't
+  // capture correct stackmap operand locations
+  assert(false && "fast register allocator not supported "
+                  "for stack transformation");
+
   DEBUG(dbgs() << "********** FAST REGISTER ALLOCATION **********\n"
                << "********** Function: " << Fn.getName() << '\n');
   MF = &Fn;
Index: lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp
===================================================================
--- lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp	(revision 277823)
+++ lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp	(working copy)
@@ -886,6 +886,9 @@
   case ISD::SRL:
   case ISD::ROTL:
   case ISD::ROTR: Res = PromoteIntOp_Shift(N); break;
+
+  case (uint16_t)~TargetOpcode::STACKMAP:
+    Res = PromoteIntOp_STACKMAP(N, OpNo); break;
   }
 
   // If the result is null, the sub-method took care of registering results etc.
@@ -1131,6 +1134,22 @@
                                 SExtPromotedInteger(N->getOperand(0))), 0);
 }
 
+SDValue DAGTypeLegalizer::PromoteIntOp_STACKMAP(SDNode *N, unsigned OpNo) {
+  std::vector<SDValue> Ops(N->getNumOperands());
+  SDLoc dl(N);
+
+  for(unsigned i = 0; i < N->getNumOperands(); i++) {
+    if(i == OpNo) {
+      if(N->getOperand(i).getValueType() == MVT::i8 ||
+         N->getOperand(i).getValueType() == MVT::i16)
+        Ops[i] = std::move(DAG.getNode(ISD::ZERO_EXTEND, dl, MVT::i32, N->getOperand(i)));
+    }
+    else Ops[i] = N->getOperand(i);
+  }
+
+  return SDValue(DAG.UpdateNodeOperands(N, Ops), 0);
+}
+
 SDValue DAGTypeLegalizer::PromoteIntOp_STORE(StoreSDNode *N, unsigned OpNo){
   assert(ISD::isUNINDEXEDStore(N) && "Indexed store during type legalization!");
   SDValue Ch = N->getChain(), Ptr = N->getBasePtr();
Index: lib/CodeGen/SelectionDAG/LegalizeTypes.h
===================================================================
--- lib/CodeGen/SelectionDAG/LegalizeTypes.h	(revision 277823)
+++ lib/CodeGen/SelectionDAG/LegalizeTypes.h	(working copy)
@@ -288,6 +288,7 @@
   SDValue PromoteIntOp_Shift(SDNode *N);
   SDValue PromoteIntOp_SIGN_EXTEND(SDNode *N);
   SDValue PromoteIntOp_SINT_TO_FP(SDNode *N);
+  SDValue PromoteIntOp_STACKMAP(SDNode *N, unsigned OpNo);
   SDValue PromoteIntOp_STORE(StoreSDNode *N, unsigned OpNo);
   SDValue PromoteIntOp_TRUNCATE(SDNode *N);
   SDValue PromoteIntOp_UINT_TO_FP(SDNode *N);
Index: lib/CodeGen/StackMaps.cpp
===================================================================
--- lib/CodeGen/StackMaps.cpp	(revision 277823)
+++ lib/CodeGen/StackMaps.cpp	(working copy)
@@ -12,7 +12,9 @@
 #include "llvm/CodeGen/MachineFrameInfo.h"
 #include "llvm/CodeGen/MachineFunction.h"
 #include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/IR/DataLayout.h"
+#include "llvm/IR/IntrinsicInst.h"
 #include "llvm/MC/MCContext.h"
 #include "llvm/MC/MCExpr.h"
 #include "llvm/MC/MCObjectFileInfo.h"
@@ -75,7 +77,7 @@
 }
 
 /// Go up the super-register chain until we hit a valid dwarf register number.
-static unsigned getDwarfRegNum(unsigned Reg, const TargetRegisterInfo *TRI) {
+unsigned StackMaps::getDwarfRegNum(unsigned Reg, const TargetRegisterInfo *TRI) {
   int RegNum = TRI->getDwarfRegNum(Reg, false);
   for (MCSuperRegIterator SR(Reg, TRI); SR.isValid() && RegNum < 0; ++SR)
     RegNum = TRI->getDwarfRegNum(*SR, false);
@@ -84,32 +86,63 @@
   return (unsigned)RegNum;
 }
 
+void StackMaps::getPointerInfo(const Value *Op,
+                               const DataLayout &DL,
+                               bool &isPtr, bool &isAlloca,
+                               unsigned &PtrDataSize) const {
+  isPtr = false;
+  isAlloca = false;
+  PtrDataSize = 0;
+
+  assert(Op != nullptr && "Invalid stackmap operand");
+  Type *Ty = Op->getType();
+  if(Ty->isPointerTy())
+  {
+    PointerType *PTy = cast<PointerType>(Ty);
+    if(PTy->getElementType()->isSized())
+    {
+      isPtr = true;
+      PtrDataSize = DL.getTypeAllocSize(PTy->getElementType());
+      if(isa<AllocaInst>(Op)) isAlloca = true;
+    }
+  }
+}
+
 MachineInstr::const_mop_iterator
 StackMaps::parseOperand(MachineInstr::const_mop_iterator MOI,
                         MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-                        LiveOutVec &LiveOuts) const {
+                        LiveOutVec &LiveOuts, User::const_op_iterator &Op) const {
+  bool isPtr, isAlloca;
+  unsigned PtrDataSize;
+  auto &DL = AP.MF->getDataLayout();
   const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  const Value *OpVal = Op->get();
+
   if (MOI->isImm()) {
+    getPointerInfo(OpVal, DL, isPtr, isAlloca, PtrDataSize);
     switch (MOI->getImm()) {
     default:
       llvm_unreachable("Unrecognized operand type.");
     case StackMaps::DirectMemRefOp: {
-      unsigned Size = AP.TM.getDataLayout()->getPointerSizeInBits();
+      unsigned Size = DL.getPointerSizeInBits();
       assert((Size % 8) == 0 && "Need pointer size in bytes.");
       Size /= 8;
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
       Locs.emplace_back(StackMaps::Location::Direct, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+                        getDwarfRegNum(Reg, TRI), Imm, isPtr, isAlloca, false,
+                        PtrDataSize);
       break;
     }
     case StackMaps::IndirectMemRefOp: {
       int64_t Size = (++MOI)->getImm();
+      int64_t AllocSize = DL.getTypeAllocSize(OpVal->getType());
       assert(Size > 0 && "Need a valid size for indirect memory locations.");
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
-      Locs.emplace_back(StackMaps::Location::Indirect, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+      Locs.emplace_back(StackMaps::Location::Indirect, AllocSize,
+                        getDwarfRegNum(Reg, TRI), Imm, isPtr, isAlloca, false,
+                        PtrDataSize);
       break;
     }
     case StackMaps::ConstantOp: {
@@ -116,10 +149,12 @@
       ++MOI;
       assert(MOI->isImm() && "Expected constant operand.");
       int64_t Imm = MOI->getImm();
-      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm);
+      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm,
+                        isPtr, isAlloca, false, PtrDataSize);
       break;
     }
     }
+    ++Op;
     return ++MOI;
   }
 
@@ -134,17 +169,101 @@
 
     assert(TargetRegisterInfo::isPhysicalRegister(MOI->getReg()) &&
            "Virtreg operands should have been rewritten before now.");
-    const TargetRegisterClass *RC = TRI->getMinimalPhysRegClass(MOI->getReg());
     assert(!MOI->getSubReg() && "Physical subreg still around.");
 
+    int64_t ID = MOI->getParent()->getOperand(0).getImm();
+    size_t valSize = DL.getTypeAllocSize(OpVal->getType());
+    getPointerInfo(OpVal, DL, isPtr, isAlloca, PtrDataSize);
+    const CallInst *SMIR = cast<CallInst>(Op->getUser());
+
+    // Check if it's been spilled to a stack slot
+    int SS = AP.MF->getSMStackSlot(SMIR, OpVal);
+    const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
+    if(MFI->getObjectIndexBegin() <= SS && SS < MFI->getObjectIndexEnd() &&
+       !MFI->isDeadObjectIndex(SS)) {
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": in stack slot " << SS << "\n";
+      );
+      int64_t Offset = MFI->getObjectOffset(SS) + 16; // RA + old FBP
+
+      Locs.emplace_back(StackMaps::Location::Indirect, valSize,
+                        getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI),
+                        Offset, isPtr, isAlloca, false, PtrDataSize);
+      ++Op;
+      return ++MOI;
+    }
+
+    // Check if it's been spilled to another register
+    unsigned PhysReg = AP.MF->getSMPhysReg(SMIR, OpVal);
+    if(!TargetRegisterInfo::isPhysicalRegister(PhysReg)) {
+      PhysReg = MOI->getReg();
+      if(AP.MF->isCallerSaved(PhysReg)) {
+        DEBUG(
+          dbgs() << "WARNING: ";
+          OpVal->printAsOperand(dbgs());
+          dbgs() << ": no spill location for caller-saved register "
+                 << getDwarfRegNum(PhysReg, TRI) << "\n";
+        );
+      }
+    }
+
     unsigned Offset = 0;
-    unsigned DwarfRegNum = getDwarfRegNum(MOI->getReg(), TRI);
+    unsigned DwarfRegNum = getDwarfRegNum(PhysReg, TRI);
     unsigned LLVMRegNum = TRI->getLLVMRegNum(DwarfRegNum, false);
-    unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, MOI->getReg());
+    unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, PhysReg);
     if (SubRegIdx)
       Offset = TRI->getSubRegIdxOffset(SubRegIdx);
 
-    Locs.emplace_back(Location::Register, RC->getSize(), DwarfRegNum, Offset);
+    DEBUG(
+      dbgs() << "Stackmap " << ID << ": ";
+      OpVal->printAsOperand(dbgs());
+      dbgs() << ": in register " << DwarfRegNum << "\n";
+    );
+
+    Locs.emplace_back(Location::Register, valSize, DwarfRegNum, Offset,
+                      isPtr, isAlloca, false, PtrDataSize);
+
+    // Check if there's a backing stack slot
+    // TODO should be able to generate records for multiple backing slots
+    SS = AP.MF->getSMBackingStackSlot(SMIR, OpVal);
+    if(MFI->getObjectIndexBegin() <= SS && SS < MFI->getObjectIndexEnd() &&
+       !MFI->isDeadObjectIndex(SS)) {
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": backed by stack slot " << SS << "\n";
+      );
+      int64_t Offset = MFI->getObjectOffset(SS) + 16; // RA + old FBP
+
+      Locs.emplace_back(StackMaps::Location::Indirect, valSize,
+                        getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI),
+                        Offset, isPtr, isAlloca, true, PtrDataSize);
+    }
+
+    // Check if there's a duplicate register
+    // TODO should be able to generate records multiple duplicates
+    PhysReg = AP.MF->getSMDupPhysReg(SMIR, OpVal);
+    if(TargetRegisterInfo::isPhysicalRegister(PhysReg)) {
+      Offset = 0;
+      DwarfRegNum = getDwarfRegNum(PhysReg, TRI);
+      LLVMRegNum = TRI->getLLVMRegNum(DwarfRegNum, false);
+      SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, PhysReg);
+      if (SubRegIdx)
+        Offset = TRI->getSubRegIdxOffset(SubRegIdx);
+
+      DEBUG(
+        dbgs() << "Stackmap " << ID << ": ";
+        OpVal->printAsOperand(dbgs());
+        dbgs() << ": duplicated in register " << DwarfRegNum << "\n";
+      );
+
+      Locs.emplace_back(Location::Register, valSize, DwarfRegNum, Offset,
+                        isPtr, isAlloca, true, PtrDataSize);
+    }
+
+    ++Op;
     return ++MOI;
   }
 
@@ -285,6 +404,7 @@
   MCContext &OutContext = AP.OutStreamer->getContext();
   MCSymbol *MILabel = OutContext.createTempSymbol();
   AP.OutStreamer->EmitLabel(MILabel);
+  User::const_op_iterator Op = nullptr;
 
   LocationVec Locations;
   LiveOutVec LiveOuts;
@@ -292,13 +412,33 @@
   if (recordResult) {
     assert(PatchPointOpers(&MI).hasDef() && "Stackmap has no return value.");
     parseOperand(MI.operands_begin(), std::next(MI.operands_begin()), Locations,
-                 LiveOuts);
+                 LiveOuts, Op);
   }
 
+  // Find the IR stackmap instruction which corresponds to MI so we can emit
+  // type information along with the value's location
+  const BasicBlock *BB = MI.getParent()->getBasicBlock();
+  const IntrinsicInst *IRSM = nullptr;
+  const std::string SMName("llvm.experimental.stackmap");
+  for(auto BBI = BB->begin(), BBE = BB->end(); BBI != BBE; BBI++)
+  {
+    const IntrinsicInst *II;
+    if((II = dyn_cast<IntrinsicInst>(&*BBI)) &&
+       II->getCalledFunction()->getName() == SMName &&
+       cast<ConstantInt>(II->getArgOperand(0))->getZExtValue() == ID)
+    {
+      IRSM = cast<IntrinsicInst>(&*BBI);
+      break;
+    }
+  }
+  assert(IRSM && "Could not find associated stackmap instruction");
+
   // Parse operands.
+  Op = std::next(IRSM->op_begin(), 2);
   while (MOI != MOE) {
-    MOI = parseOperand(MOI, MOE, Locations, LiveOuts);
+    MOI = parseOperand(MOI, MOE, Locations, LiveOuts, Op);
   }
+  assert(Op == (IRSM->op_end() - 1) && "did not lower all stackmap operands");
 
   // Move large constants into the constant pool.
   for (auto &Loc : Locations) {
@@ -327,8 +467,8 @@
       MCSymbolRefExpr::create(MILabel, OutContext),
       MCSymbolRefExpr::create(AP.CurrentFnSymForSize, OutContext), OutContext);
 
-  CSInfos.emplace_back(CSOffsetExpr, ID, std::move(Locations),
-                       std::move(LiveOuts));
+  CSInfos.emplace_back(AP.CurrentFnSym, CSOffsetExpr, ID,
+                       std::move(Locations), std::move(LiveOuts));
 
   // Record the stack size of the current function.
   const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
@@ -411,8 +551,11 @@
 /// StkSizeRecord[NumFunctions] {
 ///   uint64 : Function Address
 ///   uint64 : Stack Size
+///   uint32 : Offset into Unwinding Section
+///   uint32 : Number of Unwinding Entries
 /// }
-void StackMaps::emitFunctionFrameRecords(MCStreamer &OS) {
+void StackMaps::emitFunctionFrameRecords(MCStreamer &OS,
+                                         const UnwindInfo *UI) {
   // Function Frame records.
   DEBUG(dbgs() << WSMP << "functions:\n");
   for (auto const &FR : FnStackSize) {
@@ -420,6 +563,15 @@
                  << " frame size: " << FR.second);
     OS.EmitSymbolValue(FR.first, 8);
     OS.EmitIntValue(FR.second, 8);
+
+    if(UI) {
+      const UnwindInfo::FuncUnwindInfo &FUI = UI->getUnwindInfo(FR.first);
+      DEBUG(dbgs() << " unwind info start: " << FUI.SecOffset
+                   << " (" << FUI.NumUnwindRecord << " entries)\n");
+      OS.EmitIntValue(FUI.SecOffset, 4);
+      OS.EmitIntValue(FUI.NumUnwindRecord, 4);
+    }
+    else OS.EmitIntValue(0, 8);
   }
 }
 
@@ -439,14 +591,20 @@
 ///
 /// StkMapRecord[NumRecords] {
 ///   uint64 : PatchPoint ID
+///   uint32 : Index of Function Record
 ///   uint32 : Instruction Offset
 ///   uint16 : Reserved (record flags)
 ///   uint16 : NumLocations
 ///   Location[NumLocations] {
-///     uint8  : Register | Direct | Indirect | Constant | ConstantIndex
-///     uint8  : Size in Bytes
-///     uint16 : Dwarf RegNum
-///     int32  : Offset
+///     uint8 (4 bits) : Register | Direct | Indirect | Constant | ConstantIndex
+///     uint8 (1 bit)  : Padding
+///     uint8 (1 bit)  : Is it a pointer?
+///     uint8 (1 bit)  : Is it an alloca?
+///     uint8 (1 bit)  : Is it a duplicate record for the same live value?
+///     uint8          : Size in Bytes
+///     uint16         : Dwarf RegNum
+///     int32          : Offset
+///     uint32         : Size of pointed-to data
 ///   }
 ///   uint16 : Padding
 ///   uint16 : NumLiveOuts
@@ -477,6 +635,7 @@
     // compilation errors this way.
     if (CSLocs.size() > UINT16_MAX || LiveOuts.size() > UINT16_MAX) {
       OS.EmitIntValue(UINT64_MAX, 8); // Invalid ID.
+      OS.EmitIntValue(UINT32_MAX, 4);
       OS.EmitValue(CSI.CSOffsetExpr, 4);
       OS.EmitIntValue(0, 2); // Reserved.
       OS.EmitIntValue(0, 2); // 0 locations.
@@ -487,6 +646,7 @@
     }
 
     OS.EmitIntValue(CSI.ID, 8);
+    OS.EmitIntValue(FnStackSize.find(CSI.Func) - FnStackSize.begin(), 4);
     OS.EmitValue(CSI.CSOffsetExpr, 4);
 
     // Reserved for flags.
@@ -494,10 +654,21 @@
     OS.EmitIntValue(CSLocs.size(), 2);
 
     for (const auto &Loc : CSLocs) {
-      OS.EmitIntValue(Loc.Type, 1);
+      //OS.EmitIntValue(Loc.Type, 1);
+      // First byte is type information, bit fields represent different values:
+      //   xxxx - type (Register, Direct, Indirect, Constant/ConstantIdx)
+      //      x - padding
+      //      x - is it a pointer?
+      //      x - is it an alloca?
+      //      x - is it a duplicate?
+      uint8_t TypeAndFlags = 0;
+      TypeAndFlags = ((uint8_t)Loc.Type) << 4 | ((uint8_t)Loc.Ptr) << 2
+                   | ((uint8_t)Loc.Alloca) << 1 | ((uint8_t)Loc.Duplicate);
+      OS.EmitIntValue(TypeAndFlags, 1);
       OS.EmitIntValue(Loc.Size, 1);
       OS.EmitIntValue(Loc.Reg, 2);
       OS.EmitIntValue(Loc.Offset, 4);
+      OS.EmitIntValue(Loc.PtrDataSize, 4);
     }
 
     // Num live-out registers and padding to align to 4 byte.
@@ -515,7 +686,7 @@
 }
 
 /// Serialize the stackmap data.
-void StackMaps::serializeToStackMapSection() {
+void StackMaps::serializeToStackMapSection(const UnwindInfo *UI) {
   (void)WSMP;
   // Bail out if there's no stack map data.
   assert((!CSInfos.empty() || (CSInfos.empty() && ConstPool.empty())) &&
@@ -539,7 +710,7 @@
   // Serialize data.
   DEBUG(dbgs() << "********** Stack Map Output **********\n");
   emitStackmapHeader(OS);
-  emitFunctionFrameRecords(OS);
+  emitFunctionFrameRecords(OS, UI);
   emitConstantPoolEntries(OS);
   emitCallsiteEntries(OS);
   OS.AddBlankLine();
Index: lib/CodeGen/StackSlotColoring.cpp
===================================================================
--- lib/CodeGen/StackSlotColoring.cpp	(revision 277823)
+++ lib/CodeGen/StackSlotColoring.cpp	(working copy)
@@ -278,6 +278,7 @@
   SmallVector<int, 16> SlotMapping(NumObjs, -1);
   SmallVector<float, 16> SlotWeights(NumObjs, 0.0);
   SmallVector<SmallVector<int, 4>, 16> RevMap(NumObjs);
+  SmallDenseMap<int, int, 16> SlotChanges;
   BitVector UsedColors(NumObjs);
 
   DEBUG(dbgs() << "Color spill slot intervals:\n");
@@ -292,7 +293,10 @@
     SlotWeights[NewSS] += li->weight;
     UsedColors.set(NewSS);
     Changed |= (SS != NewSS);
+    if(SS != NewSS) SlotChanges[SS] = NewSS;
   }
+  MF.updateSMStackSlotRefs(SlotChanges);
+  MF.updateSMBackingStackSlotRefs(SlotChanges);
 
   DEBUG(dbgs() << "\nSpill slots after coloring:\n");
   for (unsigned i = 0, e = SSIntervals.size(); i != e; ++i) {
Index: lib/CodeGen/StackTransformMetadata.cpp
===================================================================
--- lib/CodeGen/StackTransformMetadata.cpp	(nonexistent)
+++ lib/CodeGen/StackTransformMetadata.cpp	(working copy)
@@ -0,0 +1,686 @@
+//=== llvm/CodeGen/StackTransformMetadata.cpp - Stack Transformation Metadata ===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file accumulates additional data from machine functions needed to do
+// correct and complete stack transformation.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/CodeGen/LiveIntervalAnalysis.h"
+#include "llvm/CodeGen/LiveStackAnalysis.h"
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/Passes.h"
+#include "llvm/CodeGen/VirtRegMap.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/Target/TargetInstrInfo.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "stacktransform"
+
+//===----------------------------------------------------------------------===//
+//                          StackTransformMetadata
+//===----------------------------------------------------------------------===//
+//
+// Run analyses over machine functions (before virtual register rewriting) to
+// glean additional information about live values.  This analysis finds
+// duplicate locations for live values, including backing stack slots and other
+// registers.
+//
+namespace {
+class StackTransformMetadata : public MachineFunctionPass {
+  MachineFunction *MF;
+  const MachineRegisterInfo *MRI;
+  const TargetInstrInfo *TII;
+  const LiveIntervals *LI;
+  const LiveStacks *LS;
+  const SlotIndexes *Indexes;
+  const VirtRegMap *VRM;
+
+  /// Operation type (copied from StackMap.h, without including everything else)
+  enum OpType { DirectMemRefOp, IndirectMemRefOp, ConstantOp };
+
+  /// A bundle tying together a stackmap IR instruction, the generated stackmap
+  /// machine instruction and the call machine instruction that caused the
+  /// stackmap to be emitted in the IR, respectively
+  typedef std::tuple<const CallInst *,
+                     const MachineInstr *,
+                     const MachineInstr *> SMInstBundle;
+
+  /// Getters for individual elements of instruction bundles
+  static inline const CallInst *getIRSM(const SMInstBundle &B) { return std::get<0>(B); }
+  static inline const MachineInstr *getMISM(const SMInstBundle &B) { return std::get<1>(B); }
+  static inline const MachineInstr *getMICall(const SMInstBundle &B) { return std::get<2>(B); }
+
+  /// Stackmap instructions & the associated call machine instruction
+  SmallVector<SMInstBundle, 32> SM;
+
+  /// Mapping between virtual registers and IR operands
+  typedef std::pair<unsigned, SmallVector<const Value *, 8> > RegValsPair;
+  typedef std::map<unsigned, SmallVector<const Value *, 8> > RegValsMap;
+
+  /// Mapping between stackmaps and the virtual registers saved by the stackmap
+  typedef std::pair<const MachineInstr *, RegValsMap> SMVregsPair;
+  typedef std::map<const MachineInstr *, RegValsMap> SMVregsMap;
+  SMVregsMap SMVregs;
+
+  /// A value's spill location
+  class SpillLoc {
+  public:
+    enum Type { NONE, VREG, STACK_LOAD, STACK_STORE };
+    unsigned Vreg;
+    SpillLoc() : Vreg(VirtRegMap::NO_PHYS_REG) {}
+    SpillLoc(unsigned Vreg) : Vreg(Vreg) {}
+    virtual SpillLoc *copy() const = 0;
+    virtual ~SpillLoc() {}
+    virtual Type getType() const = 0;
+  };
+
+  /// A spill to a stack slot
+  class StackSpillLoc : public SpillLoc {
+  public:
+    int StackSlot;
+    StackSpillLoc() : StackSlot(VirtRegMap::NO_STACK_SLOT) {}
+    StackSpillLoc(unsigned Vreg, int StackSlot) :
+                      SpillLoc(Vreg), StackSlot(StackSlot) {}
+    virtual SpillLoc *copy() const = 0;
+    virtual Type getType() const = 0;
+  };
+
+  /// A load from a stack slot
+  class StackLoadLoc : public StackSpillLoc {
+  public:
+    StackLoadLoc() {}
+    StackLoadLoc(unsigned Vreg, int StackSlot) :
+                     StackSpillLoc(Vreg, StackSlot) {}
+    virtual SpillLoc *copy() const {
+      return new StackLoadLoc(Vreg, StackSlot);
+    }
+    virtual Type getType() const { return SpillLoc::STACK_LOAD; }
+  };
+
+  /// A store to a stack slot
+  class StackStoreLoc : public StackSpillLoc {
+  public:
+    StackStoreLoc() {}
+    StackStoreLoc(unsigned Vreg, int StackSlot) :
+                      StackSpillLoc(Vreg, StackSlot) {}
+    virtual SpillLoc *copy() const {
+      return new StackStoreLoc(Vreg, StackSlot);
+    }
+    virtual Type getType() const { return SpillLoc::STACK_STORE; }
+  };
+
+  /// A spill to another register
+  class RegSpillLoc : public SpillLoc {
+  public:
+    unsigned SrcVreg;
+    RegSpillLoc() : SrcVreg(VirtRegMap::NO_PHYS_REG) {}
+    RegSpillLoc(unsigned DefVreg, unsigned SrcVreg) :
+                    SpillLoc(DefVreg), SrcVreg(SrcVreg) {}
+    virtual SpillLoc *copy() const {
+      return new RegSpillLoc(Vreg, SrcVreg);
+    }
+    virtual Type getType() const { return SpillLoc::VREG; }
+  };
+
+  /// Gather stackmap machine instructions, the IR instructions which generated
+  /// the stackmaps, and their associated call machine instructions
+  void bundleStackmaps();
+
+  /// Find stackmap operands that have been spilled to alternate locations
+  void findSpilledStackmapOps();
+
+  /// Find architecture-specific live values added by the backend
+  void findArchSpecificLiveVals();
+
+  /// Find all virtual register operands in a stackmap and collect virtual
+  /// register/IR value mappings
+  void findVregOps(const CallInst *IRSM,
+                   const MachineInstr *MISM);
+
+  /// Unwind live value movement in the series of instructions between a call
+  /// and a stackmap
+  void unwindToCall(const SMInstBundle &SM);
+
+  /// Analyze a machine instruction to see if a value is getting restored
+  /// from a spill location.
+  SpillLoc *getSpillLocation(const MachineInstr *MI) const;
+
+  /// Return whether or not a virtual registers is defined within a range of
+  /// machine instructions, inclusive
+  const MachineInstr *definedInRange(const MachineInstr *Start,
+                                     const MachineInstr *End,
+                                     unsigned Vreg) const;
+
+  /// Find if a virtual register is backed by a stack slot
+  int findBackingStackSlots(unsigned Vreg, const MachineInstr *SM);
+public:
+  static char ID;
+  StackTransformMetadata() : MachineFunctionPass(ID) {}
+
+  void getAnalysisUsage(AnalysisUsage &AU) const override;
+
+  bool runOnMachineFunction(MachineFunction&) override;
+};
+} // end anonymous namespace
+
+char &llvm::StackTransformMetadataID = StackTransformMetadata::ID;
+
+INITIALIZE_PASS_BEGIN(StackTransformMetadata, "stacktransformmetadata",
+  "Analyze functions for additional stack transformation metadata", false, true)
+INITIALIZE_PASS_DEPENDENCY(SlotIndexes)
+INITIALIZE_PASS_DEPENDENCY(LiveIntervals)
+INITIALIZE_PASS_DEPENDENCY(LiveStacks)
+INITIALIZE_PASS_DEPENDENCY(VirtRegMap)
+INITIALIZE_PASS_END(StackTransformMetadata, "stacktransformmetadata",
+  "Analyze functions for additional stack transformation metadata", false, true)
+
+char StackTransformMetadata::ID = 0;
+
+void StackTransformMetadata::getAnalysisUsage(AnalysisUsage &AU) const {
+  AU.setPreservesAll();
+  AU.addRequired<LiveIntervals>();
+  AU.addRequired<LiveStacks>();
+  AU.addRequired<SlotIndexes>();
+  AU.addRequired<VirtRegMap>();
+  MachineFunctionPass::getAnalysisUsage(AU);
+}
+
+bool StackTransformMetadata::runOnMachineFunction(MachineFunction &fn) {
+  MF = &fn;
+  TII = MF->getSubtarget().getInstrInfo();
+  MRI = &MF->getRegInfo();
+  Indexes = &getAnalysis<SlotIndexes>();
+  LI = &getAnalysis<LiveIntervals>();
+  LS = &getAnalysis<LiveStacks>();
+  VRM = &getAnalysis<VirtRegMap>();
+  SM.clear();
+  SMVregs.clear();
+
+  if(MF->getFrameInfo()->hasStackMap()) {
+    DEBUG(
+      dbgs() << "\n********** STACK TRANSFORMATION METADATA **********\n"
+             << "********** Function: " << MF->getName() << '\n';
+      VRM->dump();
+    );
+
+    bundleStackmaps();
+    findSpilledStackmapOps();
+    findArchSpecificLiveVals();
+  }
+
+  return false;
+}
+
+/// Gather stackmap machine instructions, the IR instructions which generated
+/// the stackmaps, and their associated call machine instructions
+void
+StackTransformMetadata::bundleStackmaps() {
+  static const std::string SMName("llvm.experimental.stackmap");
+  for(auto MBB = MF->begin(), MBBE = MF->end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), MIE = MBB->instr_end();
+        MI != MIE;
+        MI++) {
+      if(MI->getOpcode() == TargetOpcode::STACKMAP) {
+        // Find the stackmap IR instruction
+        assert(MI->getOperand(0).isImm() && "Invalid stackmap ID");
+        int64_t ID = MI->getOperand(0).getImm();
+        const BasicBlock *BB = MI->getParent()->getBasicBlock();
+        const CallInst *SMIR = nullptr;
+        for(auto I = BB->begin(), IE = BB->end(); I != IE; I++)
+        {
+          const IntrinsicInst *II;
+          if((II = dyn_cast<IntrinsicInst>(&*I)) &&
+             II->getCalledFunction()->getName() == SMName &&
+             cast<ConstantInt>(II->getArgOperand(0))->getSExtValue() == ID) {
+            SMIR = cast<CallInst>(II);
+            break;
+          }
+        }
+        assert(SMIR && "Could not find stackmap IR instruction");
+
+        // Find the call instruction
+        const MachineInstr *MCI = MI->getPrevNode();
+        while(MCI != nullptr) {
+          if(MCI->isCall()) {
+            if(MCI->getOpcode() == TargetOpcode::STACKMAP)
+              MCI = nullptr;
+            break;
+          }
+          MCI = MCI->getPrevNode();
+        }
+
+        if(!MCI) {
+          DEBUG(
+            dbgs() << "WARNING: stackmap " << ID << " ";
+            SMIR->printAsOperand(dbgs());
+            dbgs() << ": could not find associated call instruction "
+                      "(lowered to a native instruction?)\n";
+          );
+          continue;
+        }
+
+        SM.push_back(SMInstBundle(SMIR, &*MI, MCI));
+      }
+    }
+  }
+}
+
+/// Find all virtual register operands in a stackmap and collect virtual
+/// register/IR value mappings
+void StackTransformMetadata::findVregOps(const CallInst *IRSM,
+                                         const MachineInstr *MISM) {
+  RegValsMap::iterator VregIt;
+  MachineInstr::const_mop_iterator MOit;
+  CallInst::const_op_iterator IRit;
+
+  // Initialize a new virtual register map for the stackmap
+  SMVregs.insert(SMVregsPair(MISM, std::move(RegValsMap())));
+
+  for(MOit = std::next(MISM->operands_begin(), 2),
+      IRit = std::next(IRSM->op_begin(), 2);
+      MOit != MISM->operands_end() && IRit != (IRSM->op_end() - 1);
+      MOit++, IRit++) {
+    // Emulate StackMaps::parseOperand to correlate IR and machine operands
+    if(MOit->isImm()) {
+      switch(MOit->getImm()) {
+      case DirectMemRefOp: MOit++; MOit++; break;
+      case IndirectMemRefOp: MOit++; MOit++; MOit++; break;
+      case ConstantOp: MOit++; break;
+      default: llvm_unreachable("Unrecognized stackmap operand type."); break;
+      }
+    } else if(MOit->isReg()) {
+      const Value *IRVal = IRit->get();
+      unsigned Reg = MOit->getReg();
+
+      assert(IRVal && "Invalid stackmap IR operand");
+      assert(TargetRegisterInfo::isVirtualRegister(Reg) &&
+             "Should not have been converted to physical registers yet");
+
+      DEBUG(
+        IRVal->printAsOperand(dbgs());
+        dbgs() << ": in vreg" << TargetRegisterInfo::virtReg2Index(Reg) << "\n";
+      );
+
+      // Because multiple IR values can map to a single virtual register,
+      // maintain a list of IR values
+      if((VregIt = SMVregs[MISM].find(Reg)) == SMVregs[MISM].end()) {
+        SmallVector<const Value *, 4> vals;
+        VregIt = SMVregs[MISM].insert(RegValsPair(Reg, std::move(vals))).first;
+      }
+      VregIt->second.push_back(IRVal);
+    } else {
+      llvm_unreachable("Unrecognized stackmap operand type.");
+    }
+  }
+  assert(IRit == (IRSM->op_end() - 1) && "Did not search all stackmap operands");
+}
+
+/// Analyze a machine instruction to see if a value is getting restored from a
+/// spill location.
+StackTransformMetadata::SpillLoc *
+StackTransformMetadata::getSpillLocation(const MachineInstr *MI) const {
+  unsigned SrcVreg = 0;
+  unsigned DefVreg = 0;
+  int SS;
+
+  assert(MI && "Invalid machine instruction");
+
+  // Is it a copy from another register?
+  if(MI->isCopy()) {
+    for(unsigned i = 0, e = MI->getNumOperands(); i != e; i++) {
+      const MachineOperand &MO = MI->getOperand(i);
+      if(MO.isReg()) {
+        if(MO.isDef()) DefVreg = MO.getReg();
+        else SrcVreg = MO.getReg();
+      }
+    }
+
+    if(TargetRegisterInfo::isVirtualRegister(SrcVreg) &&
+       TargetRegisterInfo::isVirtualRegister(DefVreg))
+      return new RegSpillLoc(DefVreg, SrcVreg);
+  }
+
+  // Is it a load from the stack?
+  if((DefVreg = TII->isLoadFromStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(DefVreg))
+      return new StackLoadLoc(DefVreg, SS);
+
+  // Is it a store to the stack?
+  if((SrcVreg = TII->isStoreToStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(SrcVreg))
+      return new StackStoreLoc(SrcVreg, SS);
+
+  // Something else
+  return nullptr;
+}
+
+/// Return whether or not a machine instruction is defined within a range of
+/// machine instructions, inclusive
+const MachineInstr *
+StackTransformMetadata::definedInRange(const MachineInstr *Start,
+                                       const MachineInstr *End,
+                                       unsigned Vreg) const {
+  assert(Start && End && "Invalid machine instruction");
+  assert(TargetRegisterInfo::isVirtualRegister(Vreg) && "Invalid register");
+  assert(Start->getParent() == End->getParent() &&
+         "Range must be contained within the same basic block");
+
+  // Search over all the vreg's definitions
+  for(MachineRegisterInfo::def_instr_iterator DI = MRI->def_instr_begin(Vreg),
+      DIE = MRI->def_instr_end();
+      DI != DIE; DI++) {
+    const MachineInstr *MI = &*DI;
+
+    // Shortcut -- are we the starting or ending instruction of the range?
+    if(MI == Start || MI == End) return MI;
+
+    // Search the range of machine instructions
+    for(const MachineInstr *Cur = Start->getNextNode();
+        Cur != End && Cur != nullptr;
+        Cur = Cur->getNextNode())
+      if(Cur == MI)
+        return MI;
+  }
+
+  // None of the definitions were within the range
+  return nullptr;
+}
+
+/// Unwind live value movement in the series of instructions between a call and
+/// a stackmap
+void StackTransformMetadata::unwindToCall(const SMInstBundle &SM) {
+  unsigned PhysReg;
+  const CallInst *IRSM = getIRSM(SM);
+  const MachineInstr *MISM = getMISM(SM), *MICall = getMICall(SM), *Cur;
+  SpillLoc *Loc, *DefChain;
+  StackLoadLoc *SLL;
+  RegSpillLoc *RSL;
+  RegValsMap &Vregs = SMVregs[MISM];
+  RegValsMap::iterator vregIt;
+
+  // Walk from call to stackmap
+  for(Cur = MICall->getNextNode(); Cur != MISM; Cur = Cur->getNextNode()) {
+    Loc = getSpillLocation(Cur);
+    if(!Loc) continue;
+    if((vregIt = Vregs.find(Loc->Vreg)) == Vregs.end()) {
+      delete Loc;
+      continue;
+    }
+
+    // We may be unwinding a chain of copies to find the original spill
+    // location.  There are 2 halting conditions for the while-loop below:
+    //
+    //  1. Restoring the vreg from a spill slot
+    //  2. Restoring the vreg from a callee-saved register allocated to a
+    //     vreg whose definition is NOT between the call and the stackmap
+    //
+    // The second condition is qualified by the location of the definition of
+    // the callee-saved vreg because the backend can generate really stupid
+    // code, e.g., on x86:
+    //
+    //    callq ...
+    //    mov -0x10(%rbp), %rbx
+    //    mov %rbx, %rcx
+    //    <stackmap machine instruction>
+    //
+    // TODO it should not possible to restore from a stack slot, then spill
+    // again before reaching the stackmap -- this would invalidate #1 above.
+    DefChain = Loc->copy();
+    while(DefChain && DefChain->getType() == SpillLoc::VREG) {
+      RSL = (RegSpillLoc *)DefChain;
+      const MachineInstr *Def = definedInRange(MICall, MISM, RSL->SrcVreg);
+
+      // Are we in a callee-saved register defined outside of the range of
+      // instructions between the call and the stackmap?
+      if(!Def && !MF->isCallerSaved(VRM->getPhys(RSL->SrcVreg)))
+          break;
+
+      assert(Def && "Invalid virtual register definition");
+      DefChain = getSpillLocation(Def);
+      delete RSL;
+    }
+
+    if(!DefChain) {
+      DEBUG(
+        dbgs() << "WARNING: couldn't resolve definition chain for vreg"
+               << TargetRegisterInfo::virtReg2Index(Loc->Vreg) << "\n"
+      );
+      delete Loc;
+      continue;
+    }
+
+    switch(DefChain->getType()) {
+    case SpillLoc::VREG:
+      RSL = (RegSpillLoc *)DefChain;
+      PhysReg = VRM->getPhys(RSL->SrcVreg);
+      assert(PhysReg != VirtRegMap::NO_PHYS_REG && "Invalid register");
+      assert(!MF->isCallerSaved(PhysReg) && "Invalid register");
+
+      for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+        DEBUG(
+          vregIt->second[sz]->printAsOperand(dbgs());
+          dbgs() << ": spilled to callee-saved register "
+                 << PrintReg(PhysReg, &VRM->getTargetRegInfo()) << " (vreg"
+                 << TargetRegisterInfo::virtReg2Index(RSL->SrcVreg) << ")\n";
+        );
+        MF->addSMOpPhysRegMapping(IRSM, vregIt->second[sz], PhysReg);
+      }
+
+      // We need to check the vreg at the head of the copy chain for spill
+      // locations instead of the vreg in the stackmap
+      Vregs[RSL->SrcVreg] = vregIt->second;
+      Vregs.erase(Loc->Vreg);
+      break;
+    case SpillLoc::STACK_LOAD:
+      SLL = (StackLoadLoc *)DefChain;
+      assert(SLL->StackSlot != VirtRegMap::NO_STACK_SLOT && "Invalid stack slot");
+
+      for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+        DEBUG(
+          vregIt->second[sz]->printAsOperand(dbgs());
+          dbgs() << ": spilled to stack slot " << SLL->StackSlot << "\n";
+        );
+        MF->addSMOpStackSlotMapping(IRSM, vregIt->second[sz], SLL->StackSlot);
+      }
+
+      // Since we've already resolved the vreg to a stack slot, remove the
+      // vreg so we don't try to find backing stack slots
+      Vregs.erase(Loc->Vreg);
+      break;
+    case SpillLoc::STACK_STORE:
+    case SpillLoc::NONE:
+    default:
+      DEBUG(
+        dbgs() << "WARNING: ignoring machine instruction:\n";
+        Cur->dump();
+      );
+      break;
+    }
+
+    delete Loc;
+    delete DefChain;
+  }
+}
+
+/// Find if a virtual register is backed by a stack slot
+int StackTransformMetadata::findBackingStackSlots(unsigned Vreg,
+                                                  const MachineInstr *SM) {
+  int ret = VirtRegMap::NO_STACK_SLOT;
+  SpillLoc *Loc;
+  StackSpillLoc *SSL;
+  SlotIndex SMIdx = Indexes->getInstructionIndex(SM), Use;
+  LiveInterval::const_iterator Seg;
+
+  for(MachineRegisterInfo::reg_instr_iterator MI = MRI->reg_instr_begin(Vreg),
+      MIE = MRI->reg_instr_end();
+      MI != MIE; MI++) {
+    Loc = getSpillLocation(&*MI);
+    if(!Loc) continue;
+
+    switch(Loc->getType()) {
+    case SpillLoc::STACK_LOAD:
+    case SpillLoc::STACK_STORE:
+      // Search for stack loads/stores associated with the vreg, and check if
+      // those stack slots are live at the same time as the stackmap
+      SSL = (StackSpillLoc*)Loc;
+      if(SSL->StackSlot >= 0 && LS->hasInterval(SSL->StackSlot)) {
+        Use = Indexes->getInstructionIndex(&*MI);
+        Seg = LS->getInterval(SSL->StackSlot).find(Use);
+        if(Seg->contains(SMIdx))
+          ret = SSL->StackSlot;
+      } else {
+        DEBUG(
+          dbgs() << "WARNING: ignoring when searching for backing slot:\n";
+          MI->dump();
+        );
+      }
+      break;
+    case SpillLoc::VREG:
+    case SpillLoc::NONE:
+    default: break;
+    }
+    delete Loc;
+  }
+
+  return ret;
+}
+
+/// Find stackmap operands that have been spilled to alternate locations
+void StackTransformMetadata::findSpilledStackmapOps()
+{
+  RegValsMap::iterator vregIt, vregEnd;
+
+  // Iterate over all stackmaps to find virtual register operands which have
+  // been spilled to the stack or to other registers
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++) {
+    const CallInst *IRSM = getIRSM(*S);
+    const MachineInstr *MISM = getMISM(*S);
+
+    DEBUG(
+      MISM->dump();
+      const MachineInstr *MICall = getMICall(*S);
+      dbgs() << "\nStackmap " << MISM->getOperand(0).getImm() << ":\n";
+      MISM->dump();
+      dbgs() << "\nInstructions between call and stackmap:\n";
+      while(MICall != MISM) {
+        MICall->dump();
+        MICall = MICall->getNextNode();
+      }
+      dbgs() << '\n';
+    );
+
+    // Get all virtual register operands & their associated IR values
+    findVregOps(IRSM, MISM);
+
+    // Walk from the call to the stackmap, reversing stackmap operand movement
+    unwindToCall(*S);
+
+    // Walk through remaining virtual register operands to see if they have a
+    // backing stack slot
+    for(vregIt = SMVregs[MISM].begin(), vregEnd = SMVregs[MISM].end();
+        vregIt != vregEnd;
+        vregIt++) {
+      int StackSlot = findBackingStackSlots(vregIt->first, MISM);
+      if(StackSlot != VirtRegMap::NO_STACK_SLOT) {
+        for(size_t sz = 0; sz < vregIt->second.size(); sz++) {
+          DEBUG(
+            vregIt->second[sz]->printAsOperand(dbgs());
+            dbgs() << ": backed by stack slot " << StackSlot << "\n"
+          );
+          MF->addSMOpBackingStackSlot(IRSM, vregIt->second[sz], StackSlot);
+        }
+      }
+    }
+  }
+}
+
+
+/// Find architecture-specific live values added by the backend
+void StackTransformMetadata::findArchSpecificLiveVals() {
+  DEBUG(
+    dbgs() << "*** Detecting live values inserted by the backend ***\n\n";
+  );
+
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++)
+  {
+    const MachineInstr *MISM = getMISM(*S);
+    DEBUG(MISM->dump(););
+
+    // Look for & handle register live-out mask
+    // TODO implement?
+    for(auto SMOp = MISM->operands_begin(), SMEnd = MISM->operands_end();
+        SMOp != SMEnd; SMOp++) {
+      if(SMOp->isRegLiveOut()) {
+        DEBUG(
+          dbgs() << "Found register live-out mask:\n";
+          SMOp->print(dbgs());
+        );
+        llvm_unreachable("Unhandled register live-out mask!\n");
+      }
+    }
+
+    // Iterate over all virtual registers to see which are live for stackmap
+    const MachineInstr *MICall = getMICall(*S);
+    SlotIndex CallIdx = Indexes->getInstructionIndex(MICall);
+    DEBUG(dbgs() << "  -> SlotIndex "; CallIdx.dump(););
+    for(unsigned i = 0; i < MRI->getNumVirtRegs(); i++) {
+      unsigned Vreg = TargetRegisterInfo::index2VirtReg(i);
+
+      // Detect if virtual register is live during function call but not
+      // recorded in stackmap
+      if(VRM->hasPhys(Vreg) && LI->hasInterval(Vreg)) {
+        const LiveInterval &interval = LI->getInterval(Vreg);
+        LiveInterval::const_iterator Seg = interval.find(CallIdx);
+        // Is it live across the call?
+        if(Seg != interval.end() && Seg->contains(CallIdx)) {
+          // Is it recorded in the stackmap?
+          if(SMVregs[MISM].find(Vreg) == SMVregs[MISM].end()) {
+            DEBUG(
+              dbgs() << "    + vreg" << i
+                     << " is in register but not in stackmap ";
+              Seg->dump();
+              for(auto def = MRI->def_instr_begin(Vreg), end = MRI->def_instr_end();
+                  def != end; def++) {
+                dbgs() << "    ->";
+                def->dump();
+              }
+            );
+            // TODO pick up here -- what do we do next?
+          }
+        }
+      }
+      // Detect if virtual register is in a stack slot during function call but
+      // not recorded in stackmap
+      else if(VRM->getStackSlot(Vreg) != VirtRegMap::NO_STACK_SLOT &&
+              LI->hasInterval(Vreg)) {
+        const LiveInterval &interval = LI->getInterval(Vreg);
+        LiveInterval::const_iterator Seg = interval.find(CallIdx);
+        // Is it live across the call?
+        if(Seg != interval.end() && Seg->contains(CallIdx)) {
+          DEBUG(dbgs() << "    + vreg" << i << " is in stack slot"
+                       << VRM->getStackSlot(Vreg) << "\n";);
+          // TODO
+        }
+      }
+
+    }
+
+    // TODO iterate over all stack objects *not* in the VRM (i.e., all stack
+    // allocated variables) and see if they're live across the call
+
+    DEBUG(dbgs() << "\n";);
+  }
+}
+
Index: lib/CodeGen/UnwindInfo.cpp
===================================================================
--- lib/CodeGen/UnwindInfo.cpp	(nonexistent)
+++ lib/CodeGen/UnwindInfo.cpp	(working copy)
@@ -0,0 +1,172 @@
+//===--------------------------- UnwindInfo.cpp ---------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/CodeGen/StackMaps.h"
+#include "llvm/CodeGen/UnwindInfo.h"
+#include "llvm/MC/MCSectionELF.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/MC/MCObjectFileInfo.h"
+#include "llvm/Target/TargetRegisterInfo.h"
+#include "llvm/Target/TargetSubtargetInfo.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "unwindinfo"
+
+static const char *UIDbg = "Unwind Info: ";
+
+void UnwindInfo::recordUnwindInfo(const MachineFunction &MF) {
+  // We *only* need this information for functions which have a stackmap, as
+  // only those function activations can be unwound during stack
+  // transformation.  This may also be a correctness criterion since we record
+  // offsets from the FBP, and not all functions may have one (stackmaps are
+  // implemented using FBPs, and thus prevent the FP-elimination optimization).
+  if(!MF.getFrameInfo()->hasStackMap()) return;
+
+  // Get this function's saved registers & FBP offset
+  const unsigned FBPOff = AP.getFBPOffset();
+  const MachineFrameInfo *MFI = MF.getFrameInfo();
+  const std::vector<CalleeSavedInfo> &CSI = MFI->getCalleeSavedInfo();
+
+  // Get DWARF register number and FBP offset using callee saved information
+  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+  CalleeSavedRegisters SavedRegs(CSI.size());
+  for(unsigned i = 0; i < CSI.size(); i++) {
+    SavedRegs[i].DwarfReg = StackMaps::getDwarfRegNum(CSI[i].getReg(), TRI);
+    SavedRegs[i].Offset = MFI->getObjectOffset(CSI[i].getFrameIdx()) + FBPOff;
+  }
+
+  // Save the information for when we emit the section
+  const MCSymbol *FuncSym = OutContext.lookupSymbol(MF.getName());
+  assert(FuncSym && "Could not find function symbol");
+  FuncCalleeSaved.insert(FuncCalleePair(FuncSym, std::move(SavedRegs)));
+}
+
+void UnwindInfo::addRegisterUnwindInfo(const MachineFunction &MF,
+                                       uint32_t MachineReg,
+                                       int32_t Offset) {
+  if(!MF.getFrameInfo()->hasStackMap()) return;
+
+  const MCSymbol *FuncSym = OutContext.lookupSymbol(MF.getName());
+  assert(FuncSym && "Could not find function symbol");
+  assert(FuncCalleeSaved.find(FuncSym) != FuncCalleeSaved.end() &&
+         "Cannot add register restore information -- function not found");
+  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+  FuncCalleeSaved[FuncSym].push_back(
+    RegOffset(StackMaps::getDwarfRegNum(MachineReg, TRI), Offset));
+}
+
+void UnwindInfo::emitUnwindInfo(MCStreamer &OS) {
+  unsigned curIdx = 0;
+  unsigned startIdx;
+  FuncCalleeMap::const_iterator f, e;
+  for(f = FuncCalleeSaved.begin(), e = FuncCalleeSaved.end(); f != e; f++) {
+    const MCSymbol *FuncSym = f->first;
+    const CalleeSavedRegisters &CSR = f->second;
+
+    assert(FuncSym && "Invalid machine function");
+    if(CSR.size() < 2)
+      DEBUG(dbgs() << "WARNING: should have at least 2 registers to restore "
+                               "(return address & saved FBP");
+
+    DEBUG(dbgs() << UIDbg << "Function " << FuncSym->getName()
+                 << " (offset " << curIdx << ", "
+                 << CSR.size() << " entries):\n");
+
+    startIdx = curIdx;
+    CalleeSavedRegisters::const_iterator cs, cse;
+    for(cs = CSR.begin(), cse = CSR.end(); cs != cse; cs++) {
+      assert(cs->DwarfReg < UINT16_MAX &&
+             "Register number too large for resolution");
+      assert(INT16_MIN < cs->Offset && cs->Offset < INT16_MAX &&
+             "Register save offset too large for resolution");
+
+      DEBUG(dbgs() << UIDbg << "  Register " << cs->DwarfReg
+                   << " saved at " << cs->Offset << "\n";);
+
+      OS.EmitIntValue(cs->DwarfReg, 2);
+      OS.EmitIntValue(cs->Offset, 2);
+      curIdx++;
+    }
+    FuncUnwindInfo FUI(startIdx, curIdx - startIdx);
+    FuncUnwindMetadata.insert(FuncUnwindPair(FuncSym, std::move(FUI)));
+  }
+}
+
+void UnwindInfo::emitAddrRangeInfo(MCStreamer &OS) {
+  FuncUnwindMap::const_iterator f, e;
+  for(f = FuncUnwindMetadata.begin(), e = FuncUnwindMetadata.end();
+      f != e;
+      f++) {
+    const MCSymbol *Func = f->first;
+    const FuncUnwindInfo &FUI = f->second;
+    OS.EmitSymbolValue(Func, 8);
+    OS.EmitIntValue(FUI.NumUnwindRecord, 4);
+    OS.EmitIntValue(FUI.SecOffset, 4);
+  }
+}
+
+/// Serialize the unwinding information.
+void UnwindInfo::serializeToUnwindInfoSection() {
+  // Bail out if there's no unwind info.
+  if(FuncCalleeSaved.empty()) return;
+
+  // Emit unwinding record information.
+  // FIXME: we only support ELF object files for now
+
+  // Switch to the unwind info section
+  MCStreamer &OS = *AP.OutStreamer;
+  MCSection *UnwindInfoSection =
+      OutContext.getObjectFileInfo()->getUnwindInfoSection();
+  OS.SwitchSection(UnwindInfoSection);
+
+  // Emit a dummy symbol to force section inclusion.
+  OS.EmitLabel(OutContext.getOrCreateSymbol(Twine("__StackTransform_UnwindInfo")));
+
+  // Serialize data.
+  DEBUG(dbgs() << "********** Unwind Info Output **********\n");
+  emitUnwindInfo(OS);
+  OS.AddBlankLine();
+
+  // Switch to the unwind address range section & emit section
+  MCSection *UnwindAddrRangeSection =
+      OutContext.getObjectFileInfo()->getUnwindAddrRangeSection();
+  OS.SwitchSection(UnwindAddrRangeSection);
+  OS.EmitLabel(OutContext.getOrCreateSymbol(Twine("__StackTransform_UnwindAddrRange")));
+  emitAddrRangeInfo(OS);
+  OS.AddBlankLine();
+
+  Emitted = true;
+}
+
+const UnwindInfo::FuncUnwindInfo &
+UnwindInfo::getUnwindInfo(const MCSymbol *Func) const {
+  assert(Emitted && "Have not yet calculated per-function unwinding metadata");
+
+  FuncUnwindMap::const_iterator it = FuncUnwindMetadata.find(Func);
+  assert(it != FuncUnwindMetadata.end() && "Invalid function");
+  return it->second;
+}
+
+void UnwindInfo::print(raw_ostream &OS) {
+  OS << UIDbg << "Function unwinding information\n";
+  FuncCalleeMap::const_iterator b, e;
+  for(b = FuncCalleeSaved.begin(), e = FuncCalleeSaved.end();
+      b != e;
+      b++) {
+    OS << UIDbg << "Function - " << b->first->getName() << "\n";
+    const CalleeSavedRegisters &CSR = b->second;
+    CalleeSavedRegisters::const_iterator br, be;
+    for(br = CSR.begin(), be = CSR.end(); br != be; br++) {
+      OS << UIDbg << "Register " << br->DwarfReg
+                  << " at offset " << br->Offset << "\n";
+    }
+  }
+}
+
Index: lib/MC/MCObjectFileInfo.cpp
===================================================================
--- lib/MC/MCObjectFileInfo.cpp	(revision 277823)
+++ lib/MC/MCObjectFileInfo.cpp	(working copy)
@@ -519,6 +519,15 @@
   DwarfAddrSection =
       Ctx->getELFSection(".debug_addr", ELF::SHT_PROGBITS, 0, "addr_sec");
 
+  UnwindAddrRangeSection =
+      Ctx->getELFSection(".stack_transform.unwind_arange", ELF::SHT_PROGBITS,
+                         0, sizeof(uint64_t) + sizeof(uint64_t), "");
+  UnwindInfoSection =
+      Ctx->getELFSection(".stack_transform.unwind", ELF::SHT_PROGBITS, 0,
+                         sizeof(uint16_t) + sizeof(int16_t), "");
+  UnwindAddrRangeSection->setAlignment(sizeof(uint64_t));
+  UnwindInfoSection->setAlignment(sizeof(uint16_t) + sizeof(int16_t));
+
   StackMapSection =
       Ctx->getELFSection(".llvm_stackmaps", ELF::SHT_PROGBITS, ELF::SHF_ALLOC);
 
Index: lib/Target/AArch64/AArch64AsmPrinter.cpp
===================================================================
--- lib/Target/AArch64/AArch64AsmPrinter.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64AsmPrinter.cpp	(working copy)
@@ -28,6 +28,7 @@
 #include "llvm/CodeGen/MachineModuleInfoImpls.h"
 #include "llvm/CodeGen/StackMaps.h"
 #include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/IR/DataLayout.h"
 #include "llvm/IR/DebugInfo.h"
 #include "llvm/MC/MCAsmInfo.h"
@@ -49,11 +50,12 @@
 class AArch64AsmPrinter : public AsmPrinter {
   AArch64MCInstLower MCInstLowering;
   StackMaps SM;
+  UnwindInfo UI;
 
 public:
   AArch64AsmPrinter(TargetMachine &TM, std::unique_ptr<MCStreamer> Streamer)
       : AsmPrinter(TM, std::move(Streamer)), MCInstLowering(OutContext, *this),
-        SM(*this), AArch64FI(nullptr) {}
+        SM(*this), UI(*this), AArch64FI(nullptr) {}
 
   const char *getPassName() const override {
     return "AArch64 Assembly Printer";
@@ -83,7 +85,9 @@
 
   bool runOnMachineFunction(MachineFunction &F) override {
     AArch64FI = F.getInfo<AArch64FunctionInfo>();
-    return AsmPrinter::runOnMachineFunction(F);
+    bool retval = AsmPrinter::runOnMachineFunction(F);
+    UI.recordUnwindInfo(F);
+    return retval;
   }
 
 private:
@@ -129,8 +133,10 @@
     // linker can safely perform dead code stripping.  Since LLVM never
     // generates code that does this, it is always safe to set.
     OutStreamer->EmitAssemblerFlag(MCAF_SubsectionsViaSymbols);
-    SM.serializeToStackMapSection();
   }
+  UI.serializeToUnwindInfoSection();
+  SM.serializeToStackMapSection(&UI);
+  UI.reset(); // Must reset after SM serialization to clear metadata
 }
 
 MachineLocation
Index: lib/Target/AArch64/AArch64ISelLowering.cpp
===================================================================
--- lib/Target/AArch64/AArch64ISelLowering.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64ISelLowering.cpp	(working copy)
@@ -2032,6 +2032,8 @@
     return LowerFSINCOS(Op, DAG);
   case ISD::MUL:
     return LowerMUL(Op, DAG);
+  case (uint16_t)~TargetOpcode::STACKMAP:
+    return SDValue(); // Use generic stackmap type legalizer
   }
 }
 
Index: lib/Target/AArch64/AArch64TargetMachine.cpp
===================================================================
--- lib/Target/AArch64/AArch64TargetMachine.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64TargetMachine.cpp	(working copy)
@@ -61,11 +61,14 @@
 EnableLoadStoreOpt("aarch64-load-store-opt", cl::desc("Enable the load/store pair"
                    " optimization pass"), cl::init(true), cl::Hidden);
 
+// Note: this optimization invalidates stackmaps inserted in the middle-end,
+// meaning AArch64 binaries are generated with different numbers of stackmaps
+// versus other backends
 static cl::opt<bool>
 EnableAtomicTidy("aarch64-atomic-cfg-tidy", cl::Hidden,
                  cl::desc("Run SimplifyCFG after expanding atomic operations"
                           " to make use of cmpxchg flow-based information"),
-                 cl::init(true));
+                 cl::init(false));
 
 static cl::opt<bool>
 EnableEarlyIfConversion("aarch64-enable-early-ifcvt", cl::Hidden,
Index: lib/Target/X86/X86AsmPrinter.cpp
===================================================================
--- lib/Target/X86/X86AsmPrinter.cpp	(revision 277823)
+++ lib/Target/X86/X86AsmPrinter.cpp	(working copy)
@@ -24,6 +24,7 @@
 #include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
 #include "llvm/IR/DebugInfo.h"
 #include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/DiagnosticInfo.h"
 #include "llvm/IR/Mangler.h"
 #include "llvm/IR/Module.h"
 #include "llvm/IR/Type.h"
@@ -49,6 +50,8 @@
 bool X86AsmPrinter::runOnMachineFunction(MachineFunction &MF) {
   Subtarget = &MF.getSubtarget<X86Subtarget>();
 
+  bool modified = TagCallSites(MF);
+
   SMShadowTracker.startFunction(MF);
 
   SetupMachineFunction(MF);
@@ -66,8 +69,19 @@
   // Emit the rest of the function body.
   EmitFunctionBody();
 
-  // We didn't modify anything.
-  return false;
+  // Add this function's register unwind info.  The x86 backend doesn't
+  // maintain the saved FBP (old RBP) and return address (RIP) as callee-saved
+  // registers, so manually add where they're saved.
+  MachineFrameInfo *MFI = MF.getFrameInfo();
+  if(MFI->hasStackMap()) {
+    const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+    UI.recordUnwindInfo(MF);
+    UI.addRegisterUnwindInfo(MF, TRI->getFrameRegister(MF), 0);
+    UI.addRegisterUnwindInfo(MF, TRI->getProgramCounter(), 8);
+  }
+
+  // We may have modified where stack map intrinsics are located.
+  return modified;
 }
 
 /// printSymbolOperand - Print a raw symbol reference operand.  This handles
@@ -689,8 +703,10 @@
   }
 
   if (TT.isOSBinFormatELF()) {
-    SM.serializeToStackMapSection();
+    UI.serializeToUnwindInfoSection();
+    SM.serializeToStackMapSection(&UI);
     FM.serializeToFaultMapSection();
+    UI.reset(); // Must reset after SM serialization to clear metadata
   }
 }
 
Index: lib/Target/X86/X86AsmPrinter.h
===================================================================
--- lib/Target/X86/X86AsmPrinter.h	(revision 277823)
+++ lib/Target/X86/X86AsmPrinter.h	(working copy)
@@ -14,6 +14,7 @@
 #include "llvm/CodeGen/AsmPrinter.h"
 #include "llvm/CodeGen/FaultMaps.h"
 #include "llvm/CodeGen/StackMaps.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/Target/TargetMachine.h"
 
 // Implemented in X86MCInstLower.cpp
@@ -28,6 +29,7 @@
 class LLVM_LIBRARY_VISIBILITY X86AsmPrinter : public AsmPrinter {
   const X86Subtarget *Subtarget;
   StackMaps SM;
+  UnwindInfo UI;
   FaultMaps FM;
 
   // This utility class tracks the length of a stackmap instruction's 'shadow'.
@@ -90,8 +92,8 @@
  public:
    explicit X86AsmPrinter(TargetMachine &TM,
                           std::unique_ptr<MCStreamer> Streamer)
-       : AsmPrinter(TM, std::move(Streamer)), SM(*this), FM(*this),
-         SMShadowTracker(TM) {}
+       : AsmPrinter(TM, std::move(Streamer)), SM(*this), UI(*this),
+         FM(*this), SMShadowTracker(TM) {}
 
   const char *getPassName() const override {
     return "X86 Assembly / Object Emitter";
